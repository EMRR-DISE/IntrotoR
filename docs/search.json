[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to R Training - July 2024",
    "section": "",
    "text": "1 Intro to R for DWR\nWelcome to the Intro to R class for the Department of Water Resources, 2024!\nFor the first time, this is not taught by outside consultants, but by your own colleagues here at the department.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to R for DWR</span>"
    ]
  },
  {
    "objectID": "index.html#ground-rules",
    "href": "index.html#ground-rules",
    "title": "Introduction to R Training - July 2024",
    "section": "1.1 Ground rules",
    "text": "1.1 Ground rules\n\nPlease participate fully in the class. You will get out of this class exactly as much as you put into it. This means not multi-tasking, completing the exercises, and asking questions when you get stuck.\nPlease come prepared. Install software ahead of time, have the link to this book on-hand, and review materials from the previous day before the next day’s class.\nDon’t be afraid to ask questions! Any coding language can be frustrating, so please speak up if you are having trouble. One of our teaching assistants can work with you 1:1 for major problems.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to R for DWR</span>"
    ]
  },
  {
    "objectID": "index.html#before-you-come-to-class",
    "href": "index.html#before-you-come-to-class",
    "title": "Introduction to R Training - July 2024",
    "section": "1.2 Before you come to class",
    "text": "1.2 Before you come to class\n\nInstall R\n\nGo to the Comprehensive R Archive Network (CRAN) webpage and download R for Windows.\nOpen the installer and follow the prompts to install R on your computer using the default settings. You may need an administrator account to complete this step.\nIf you already have R on your computer, please make sure it is version 4.0 or above. (The latest version is 4.4.1)\nSee full instructions here: https://rstudio-education.github.io/hopr/starting.html\n\nInstall R Studio\n\nGo to the Download Rstudio page on the Posit website and download R Studio for Windows.\nOpen the installer and follow the prompts to install R on your computer using the default settings. You may need an administrator account to complete this step.\n\nOpen RStudio and make sure it runs.\n\nThe window titled “Console” should come up and have the R version and some boilerplate information about R in it, with a blue carrot and cursor below it.\n\n\n\n\nInstall the tidyverse and here packages\n\nIn your console, type install.packages(\"tidyverse\", \"here\")\nThe package should download and install automatically. You do not need administrative privileges for this step.\nNOTE: There are sometimes issues accessing CRAN from within RStudio while connected to a DWR network. If you receive this message, use your home wifi or a cell phone hot spot to connect to the internet, then try again.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to R for DWR</span>"
    ]
  },
  {
    "objectID": "index.html#meet-your-instructors",
    "href": "index.html#meet-your-instructors",
    "title": "Introduction to R Training - July 2024",
    "section": "1.3 Meet your instructors",
    "text": "1.3 Meet your instructors\n\nRosemary Hartman (She/Her) is an Environmental Program Manager in the Division of Integrated Science and Engineering. She is an aquatic ecologist by training, with an emphasis on data synthesis, statistics, and data integration. She would love to tell you how to analyze your data.\nPerry (They/Them) is an Environmental Scientist with the Environmental Monitoring Program who is also getting a master’s degree in statistics from UC Davis. They are fluent in both Python and R.\nNick Rasmussen (He/Him) is a Senior Environmental Scientist with broad interests in aquatic ecology who has worked on projects ranging from the Salinity Control Gates to aquatic weeds.\nDave Bosworth (He/Him) is a Senior Environmental Scientist who comes from a water quality and contaminants background but has found his calling as a data scientist. He is passionate about making your code more efficient and automating all the boring stuff.\nTed Swift (He/Him) is a Senior Environmental Scientist with the Quality Management Section who is working to increase the number of data science training available to DWR scientists.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Intro to R for DWR</span>"
    ]
  },
  {
    "objectID": "code/Day1Intro.html",
    "href": "code/Day1Intro.html",
    "title": "\n2  An introduction to R\n",
    "section": "",
    "text": "2.1 R\nR is a flexible coding language that anyone can learn\nI am taking a lot of this tutorial from the e-book “Hands on Programming in R” https://rstudio-education.github.io/hopr/\nIsn’t R a language?\nYou may hear me speak of R in the third person. For example, I might say, “Tell R to do this” or “Tell R to do that”, but of course R can’t do anything; it is just a language. This way of speaking is shorthand for saying, “Tell your computer to do this by writing a command in the R language at the command line of your RStudio console.” Your computer, and not R, does the actual work.\nIs this shorthand confusing and slightly lazy to use? Yes. Do a lot of people use it? Everyone I know–probably because it is so convenient.\nRstudio - integrated development environment",
    "crumbs": [
      "Day 1: 7/9/2024",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>An introduction to R</span>"
    ]
  },
  {
    "objectID": "code/Day1Intro.html#why-use-code",
    "href": "code/Day1Intro.html#why-use-code",
    "title": "\n2  An introduction to R\n",
    "section": "\n2.2 Why use code?",
    "text": "2.2 Why use code?\nThere is a very steep learning curve to R (or any coding language). You are likely to get frustrated when code doesn’t work. The first things you learn are probably things you could do easier and faster in Excel. So why bother?\n\nReproducibility. Your workflow will be documented and can be repeated quickly and easily. It is also easier to fix your mistakes because you can see exactly what you did in every step of the process!\nLarge datasets. The larger your dataset is, the more difficult it will be to analyze in Excel or other GUI-based programs.\nAdvanced statistical capabilities. You can go a lot further with tools like mixed models, multivariate analyses, machine learning, and population models that are impossible in Excel.\nHuge crowd-sourced base of packages and help. The R community is really what makes it special. Pretty much anything you want to do has probably been done before, and there is a publicly-available package to help you out.",
    "crumbs": [
      "Day 1: 7/9/2024",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>An introduction to R</span>"
    ]
  },
  {
    "objectID": "code/Day1Intro.html#part-1-the-very-basics",
    "href": "code/Day1Intro.html#part-1-the-very-basics",
    "title": "\n2  An introduction to R\n",
    "section": "\n2.3 Part 1: The Very basics",
    "text": "2.3 Part 1: The Very basics\nOK, everyone, open Rstudio. Click on the new project button. A ‘project’ is basically an organized directory that has all of the data, code, and outputs for a particular work product. It’s especially useful once you start working on multiple files and reading in and out data and stuff, so it’s good to get in the habit of always working in a project. For now, choose a location for a folder that will contain all the work you want to do for this class. This folder is your “working directory”, meaning, the default location for loading inputs and writing outputs, scripts, etc.\n\nNow let’s take a look at your RStudio Screen. Go over the different panes and how to navigate and customize.\nThis should be in your console:\n\nNow go to File –&gt; new file –&gt; R script.\nThis will be your first R script. You will type things in the script, then transfer them to the console to run them. You can technically type directly into the console, but then you can’t save them, and that’s bad, so get into the habit of writing everything in your script.\n\n2.3.1 Comments\nAnother good habit to start early is commenting your code. Comments are indicated by hashtags #. They are parts of your script that don’t do anything, just give you information about what you intended in your code and why you did what you did. RStudio helpfully color-codes them for you.\nFor example:\n\n#This is my first R script\n\n#test out addition\n1+1\n\n[1] 2\n\n#use a function\nsum(c(1,1))\n\n[1] 2\n\n\n\n2.3.2 Running code\nFrom your script, you can hit the ‘Run’ icon in the top right corner to move a line of code from your script to your console.\nYou can also hit ctrl+enter to do the same thing.\nHighlight multiple lines of code to run more than one thing at once.\nThe “source” button at the top of the script runs the entire script at once without printing all the output. This is useful of you have a script that is mostly setup stuff or homemade functions.\nYou will notice that in the console all the lines of code you run start with a &gt;. If you have multiple lines of code strung together, there will be + at the start of the new lines until the end of the code. In an R script, you can break your code up into lines to make it all fit on your screen, so long as the parentheses line up.\nThe output does not start with a carrot or plus sign. (explain the brackets)\n\n2.3.3 Exercise\nNow your turn!\n\nUse comments to write a title, date, and your name at the top of the script.\nSave your script in your project working directory\nType 24/2 in your script\nRun the script\n\nClick below for the answer when you are done!\n\nCode# My First R script\n#\n\n24/2",
    "crumbs": [
      "Day 1: 7/9/2024",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>An introduction to R</span>"
    ]
  },
  {
    "objectID": "code/Day1Intro.html#part-2-objects-and-assignment",
    "href": "code/Day1Intro.html#part-2-objects-and-assignment",
    "title": "\n2  An introduction to R\n",
    "section": "\n2.4 Part 2: Objects and Assignment",
    "text": "2.4 Part 2: Objects and Assignment\nThe joy of coding is that you can quickly to a lot of things at once. So, if I had a dataset with temperatures in Fahrenheit that I want to convert to Celsius, we can use R to do that all at once.\nLet’s say our list of temperatures are: 72, 69, 57, 58, 71, 64, 65, 70, 59\nWe can use R like a calculator to convert each of these numbers\n\n(72-32)*5/9\n\n[1] 22.22222\n\n(69-32)*5/9\n\n[1] 20.55556\n\n(57-32)*5/9\n\n[1] 13.88889\n\n(58-32)*5/9\n\n[1] 14.44444\n\n(71-32)*5/9\n\n[1] 21.66667\n\n(64-32)*5/9\n\n[1] 17.77778\n\n(65-32)*5/9\n\n[1] 18.33333\n\n(70-32)*5/9\n\n[1] 21.11111\n\n(59-32)*5/9\n\n[1] 15\n\n\nBut that’s tedious. Instead, we can clump these numbers together into a vector and assign it to a variable.\nLet’s call our vector “temps”\n\ntemps &lt;- c(72, 69, 57, 58, 71, 64, 65, 70, 59)\n\ntemps\n\n[1] 72 69 57 58 71 64 65 70 59\n\n\nThe &lt;- is called the “assignment operator”. You can also use = to do the same thing. The c is short for “concatenate”, which means “stick all these things together”. We now have an object temps that is a vector of values. Type “temps” into your console.\nWe can then perform operations on the whole vector of values at once. For example\n\n(temps-32)*5/9\n\n[1] 22.22222 20.55556 13.88889 14.44444 21.66667 17.77778 18.33333 21.11111\n[9] 15.00000\n\n\nIf we want to save that output, we need to assign it to a new variable\n\ntemps_C &lt;- (temps-32)*5/9\n\nNote that this doesn’t give you any output, it just assigns a value to temps_C. If we want to see what temps_C is, we need to print it out.\n\ntemps_C\n\n[1] 22.22222 20.55556 13.88889 14.44444 21.66667 17.77778 18.33333 21.11111\n[9] 15.00000\n\n\nIf you want to print it as you make the assignment, you can put parentheses around it.\n\n(temps_C2 &lt;- temps_C*2)\n\n[1] 44.44444 41.11111 27.77778 28.88889 43.33333 35.55556 36.66667 42.22222\n[9] 30.00000\n\n\nYou’ll also notice that in the Environment tab in your Rstudio window you should now have temps and temps_C. You can click on them to see them.\n\n2.4.1 Exercise\nConvert these numbers from miles per hour to meters per second. (use assignment)\n21, 25, 100, 50, 36, 72, 15\nClick below for the answer when you are done.\n\nCode#the variable \"mph\" will be assigned the value of a vector of all our numbers\nmph &lt;- c(21, 25, 100, 50, 36, 72, 15)\n\n#to convert mph to mps, divide by 2.237\nmps &lt;- mph/2.237\n\n#now print the output\nmps\n\n\n\n2.4.2 Type of objects\nWe can call temps and temps_C objects. Specifically, they are numeric vectors. Let’s go through some different types of objects.\n\nScalars - single value\nVectors - list if values (one dimensional)\nMatrices - values in rows and columns, all the same type (two dimensional)\nArrays - multiple matrices stacked up (three-dimensional)\nData Frames - Data of different types in rows and columns, where all columns are the same length and all rows are the same width.\nLists - data of different types and different lengths in rows and columns.\n\n2.4.3 Data classes\n\nnumeric - Numbers (duh), these can be integers, real numbers, etc.\ncharacter - Any sequence of letters and numbers\nlogical - TRUE/FALSE (always in all caps)\nfactor - Categorical variables that take a limited set of values. May be ordered (like water year types), or unordered (like families of fishes)\ndate/time classes (giant can of worms)\n\nUsing class and str to get info about objects. also View and head.\n\nfoo &lt;- \"Cat\"\ndog &lt;- 24\n\nclass(foo)\n\n[1] \"character\"\n\nstr(foo)\n\n chr \"Cat\"\n\nclass(dog)\n\n[1] \"numeric\"\n\nfoo2 = c(\"Cat\", \"dog\", \"Mouse\", \"Squirrel\")\nstr(foo2)\n\n chr [1:4] \"Cat\" \"dog\" \"Mouse\" \"Squirrel\"\n\n\n\n2.4.4 Functions\nFunctions are little sequences of code that do something useful. There are lots of built-in functions, plus you can define your own functions when you get a little more practice.\nThe basic structure is:\nfunction(arguments)\nwhere “arguments” are the inputs to your function.\nThe parentheses are the “trigger” that tells R to run the function. Typing the name of the function without the parentheses prints the code in the console. And you can write your own when you get good.\n\n#when we calculated the sum of 1 +1, that was a function\n\nsum(1+1)\n\n[1] 2\n\nsum\n\nfunction (..., na.rm = FALSE)  .Primitive(\"sum\")\n\n#mean is another useful function\nmean(c(1,2,3,4))\n\n[1] 2.5\n\n\nNotice that as you start typing the function, a box pops up in RStudio that prompts you with the arguments you might want to use. Also note that we have to “feed” the mean function a vector of values with c (concatenate) in front of it.\n\n2.4.4.1 Exercise\nSee if you can use use these functions\n\nmean - calculate the mean of 23, 24, 15, 12, 53, 23, 1, 45\n\nsum - calculate the sum of all numbers below 50\n\nHint! You can ask for a sequence of numbers with a : between the first and last number.\n\n\nabs (absolute value)\nlog - default is ln, not log10\nround - can specify decimal places\n\nexp (exponent)\nClick below for the answers when you’re done!\n\n\n\nCodemean(c(23, 24, 15, 12, 53, 23, 1, 45))\n\nsum(c(1:50))\n\nabs(c(-1, 2, -10, 5))\n\n#natural log\nlog(100)\n\n#log base 10\nlog(100, base = 10)\n\n#the default for round is no decimal points\nround(5.345673)\n\n#but you can specify the number of decimal points with the second argument\nround(5.345673, digits = 2)\n\n#this is the same as e^20\nexp(20)\n\nexp(log(10))",
    "crumbs": [
      "Day 1: 7/9/2024",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>An introduction to R</span>"
    ]
  },
  {
    "objectID": "code/Day1Intro.html#part-3-packages",
    "href": "code/Day1Intro.html#part-3-packages",
    "title": "\n2  An introduction to R\n",
    "section": "\n2.5 Part 3: Packages",
    "text": "2.5 Part 3: Packages\nThe real benefit of R is that it is open-source, and tons and tons of people have developed ‘expansion packs’ for R. You can go a very long way with just the built-in R functions, but many people have developed slightly different ways of doing things, easier methods, and more advanced things.\nLet’s go over to the R website and talk packages - https://www.r-project.org/\nWe had everyone install the tidyverse packages before getting started. This is actually a set of packages that all work together to make code a little more intuitive. Let’s go over to the “Packages” tab in RStudio and check them out.\n\ndplyr - data manipulation\nlubridate - dates and times\nggplot2 - graphics\ntidyr - more data manipulation\nforcats - working with categorical variables (factors)\nreadr - importing data from spreadsheets\nstringr - working with character strings\ntibble - nicer checking and formatting for tables and data frames\n\nYou’ll notice that besides the tidyverse, there are a number of other packages in this tab that you didn’t install - they came along with base R.\nWhen you want to install or update packages, you can use the install.packages command, or the GUI in RStudio. This command reaches out to (incomplete). You only have to do this once. However, at the start of every R session you will need to load the package into your environment using the library command. This is usually done at the top of your script.\n\n#load required libraries\nlibrary(readr)\n\nLet’s check out the documentation\n\n#check out documentation\n?readr\n\nClick on the index, then one of the vignettes - those are very useful!\n\n\n2.5.1 Package conflicts\nAfter you’ve loaded a package, you might get some warnings about conflicted packages. These are different functions with the same name in two different packages. Mostly it isn’t a problem, but sometimes you’ll have to specify which function you mean.\nSpecify which you want with package::function\n\nlibrary(lubridate)\n\nIf you really want the base version instead of the one from a package, you can use the exclude argument.\n\n#remove the lubrdate library we just loaded\ndetach(\"package:lubridate\")\n\n#now reload with the exclusion\nlibrary(lubridate, exclude = \"date\")\n\n\n2.5.2 Exercise\nLet’s try using a function that is in a package. glimpse is an simple function that tells you about a data frame. R has a number of built-in data sets that you can play with, and one is mtcars. It’s just a table of different makes and models of cars and their stats.\n\n#The View function is built in. \nView(mtcars)\n\n\n#the \"glimpse\" function is in the dplyr package. It's part of the tidyverse set of packages. You should have installed it already\nglimpse(mtcars)\n\nError in glimpse(mtcars): could not find function \"glimpse\"\n\n\nEven though you installed it, you still need to load it into your workspace using the library command.\n\nlibrary(dplyr)\n\nglimpse(mtcars)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\n\n\n2.5.3 Exercise\nNow go to the documentation for dplyr and look through the “Introduction to dplyr” vignette. Take 10 mins and see if you try out some of the examples. We’ll be using a lot of these dplyr functions later in the class.\n\n?dplyr\n\nvignette(\"dplyr\")",
    "crumbs": [
      "Day 1: 7/9/2024",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>An introduction to R</span>"
    ]
  },
  {
    "objectID": "code/Day1Intro.html#part-4-errors-and-getting-help",
    "href": "code/Day1Intro.html#part-4-errors-and-getting-help",
    "title": "\n2  An introduction to R\n",
    "section": "\n2.6 Part 4: Errors and Getting Help",
    "text": "2.6 Part 4: Errors and Getting Help\nOne of the most frustrating parts of coding is errors. Your computer is very good at doing exactly what you tell it to, but that might not be what you want.\n\ndates = c(\"Monday\", \"Tuesday\", \"Wednesday\")\n\ndate[1]\n\nError in date[1]: object of type 'closure' is not subsettable\n\n\nThis is one of my least favorite error messages. What the heck does that even mean?\nIt turns out we accidentally typed date instead of dates, and date is a reserved term in R, so it was trying to subset a word that designates a data type and everyone was confused. But don’t worry! It gets worse.\nEveryone has trouble interpreting error messages at first. Fortunately, error messages are improving, and you will get better at understanding them.\nAnother thing to know is that not all red text is errors. Some are warnings. Don’t worry about what this code does for now, just see what the output looks like.\n\nlibrary(ggplot2)\n\n\nmtcars[1,1] = NA \n\nggplot(mtcars, aes(x = mpg, y = hp))+ geom_point()+ geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nEverything still ran, but it gave to a warning to let you know something did not go as planned.\nWe also sometimes get messages, which are usually not even red.\n\n#don't worry about what this code does for now, just notice that we get a message telling you what it decided to use for the smoothing term.\nggplot(mtcars, aes(x = mpg, y = hp))+ geom_point()+ geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\nThe first thing to learn, is how to read the documentation for a function.\n\n?mean\n\nThe documentation has a few standard parts\n\nfunction and package in curly brackets at top\nTitle\nDescription- Frequently not all that helpful, but sometimes useful\n\nUsage (Function and arguments)\n\n\n\nArguments - description of what all the arguments should contain\n\n\n\nValue - output\n\n\nReferences - articles or more info\nSee Also - similar functions or functions you might want if you want this one\n\n\nExamples - THE MOST USEFUL PART!\n\n\nSometimes there are other parts, including more details on statistical methods, but these are the basics.\n\n\n2.6.1 Exercise\nLook up the documentation for these functions and see if you can run the examples.\nrnorm\naov\nsample\nClick below to see the answer when you are done.\n\nCode?rnorm\n#rnorm generates a random number or numbers from a normal distribution. You can specify the mean and standard deviation\n\n#this generates 20 random numbers with a mean of 10 and a standard deviation of 3\nrnorm(20, mean = 10, sd =3)\n\n?aov\n#aov runs an ANOVA (analysis of variance), which tests for differences between groups\n\n#the examples use the \"npk\" dataset which is built into R\naov(yield ~ block + N * P + K, npk)\n\n?sample\n#this function takes a subsample of a larger set of number of a specified size \n\nx &lt;- 1:12\n# a random permutation\nsample(x)\n# bootstrap resampling -- only if length(x) &gt; 1 !\nsample(x, replace = TRUE)\n\n\n\n2.6.2 Online help options\n\nhttps://rseek.org/\nhttps://chatgpt.com/\nhttps://posit.co/resources/cheatsheets/",
    "crumbs": [
      "Day 1: 7/9/2024",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>An introduction to R</span>"
    ]
  },
  {
    "objectID": "code/Day1Intro.html#closing-for-the-day",
    "href": "code/Day1Intro.html#closing-for-the-day",
    "title": "\n2  An introduction to R\n",
    "section": "\n2.7 Closing for the day",
    "text": "2.7 Closing for the day\nHow to save your workspace image.\n\nsave.image()\n#also little save icon on environment\n\nHow to clear your workspace.\n\nrm(list = ls())\n#also little broom icon on the environment",
    "crumbs": [
      "Day 1: 7/9/2024",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>An introduction to R</span>"
    ]
  },
  {
    "objectID": "code/Day2_DataOrg.html",
    "href": "code/Day2_DataOrg.html",
    "title": "\n3  Data Manipulation\n",
    "section": "",
    "text": "3.1 Working with Data in R\nAs data scientists, our goal to use our collected data to produce statistics and graphics that inform various management and scientific questions. In order to do this, we must first learn how to properly format our data in R. Practically, this means learning basic processes for formatting data frames.",
    "crumbs": [
      "Day 2: 7/11/2024",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulation</span>"
    ]
  },
  {
    "objectID": "code/Day2_DataOrg.html#load-packages",
    "href": "code/Day2_DataOrg.html#load-packages",
    "title": "\n3  Data Manipulation\n",
    "section": "\n3.2 Load Packages",
    "text": "3.2 Load Packages\nOne of the most important “packages” for this task is tidyverse, which we learned about yesterday. We’ll import it here:\n\nlibrary(tidyverse)",
    "crumbs": [
      "Day 2: 7/11/2024",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulation</span>"
    ]
  },
  {
    "objectID": "code/Day2_DataOrg.html#subset-by-column-name",
    "href": "code/Day2_DataOrg.html#subset-by-column-name",
    "title": "\n3  Data Manipulation\n",
    "section": "\n6.1 Subset by Column Name",
    "text": "6.1 Subset by Column Name\nSubsetting is very powerful, but one issue is – by access values by their numerical index – we can get confused about what we’re accessing. For example, if I wanted to work with DissAmmonia data, I would have to first know that it’s the 4th column in my dataframe. That can get unwieldy with complex datasets.\nInstead, we can use the column header to call a particular column:\n\ndf_wq['DissAmmonia']\n\n# A tibble: 62 × 1\n   DissAmmonia\n         &lt;dbl&gt;\n 1        0.15\n 2        0.21\n 3        0.25\n 4        0.14\n 5        0.11\n 6        0.22\n 7        0.05\n 8        0.05\n 9        0.05\n10        0.05\n# ℹ 52 more rows\n\n\n\nstr(df_wq['DissAmmonia'])\n\ntibble [62 × 1] (S3: tbl_df/tbl/data.frame)\n $ DissAmmonia: num [1:62] 0.15 0.21 0.25 0.14 0.11 0.22 0.05 0.05 0.05 0.05 ...\n\n\nThis returns a tibble that only contains the relevant column.\nWe can also call the column as a vector (this is the more common syntax):\n\ndf_wq$DissAmmonia\n\n [1] 0.150 0.210 0.250 0.140 0.110 0.220 0.050 0.050 0.050 0.050 0.050 0.050\n[13] 0.062 0.060 0.050 0.050 0.050 0.123 0.299 0.135 0.063 0.078 0.050 0.093\n[25] 0.056 0.058 0.050 0.050 0.050 0.050 0.069 0.050 0.069 0.073 0.118 0.186\n[37] 0.090 0.192 0.113 0.107 0.053 0.106 0.086 0.050 0.081 0.060 0.050 0.056\n[49] 0.128 0.145 0.290 0.145 0.070 0.109 0.068 0.050 0.050 0.050 0.061 0.070\n[61] 0.061 0.168\n\n\n\nstr(df_wq$DissAmmonia)\n\n num [1:62] 0.15 0.21 0.25 0.14 0.11 0.22 0.05 0.05 0.05 0.05 ...\n\n\nTo select multiple columns by name, we use our : technique within the select function from the dplyr package (in tidyverse):\n\ndf_wq %&gt;% select(Station:Pheophytin)\n\n# A tibble: 62 × 4\n   Station Date        Chla Pheophytin\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 P8      2020-01-16  0.64       0.5 \n 2 D7      2020-01-22  0.67       0.87\n 3 P8      2020-02-14  1.46       0.69\n 4 D7      2020-02-20  2.15       0.5 \n 5 P8      2020-03-03  1.4        0.56\n 6 D7      2020-03-06  1.89       1.13\n 7 P8      2020-06-11  4.73       1.25\n 8 D7      2020-06-17  1.74       0.89\n 9 P8      2020-07-13  6.4        0.88\n10 D7      2020-07-16  2.79       0.85\n# ℹ 52 more rows\n\n\nIf this is the only data I want to work with, I can store this as a unique object:\n\ndf_chlpheo &lt;- df_wq %&gt;% select(Station:Pheophytin)\n\n\nglimpse(df_chlpheo)\n\nRows: 62\nColumns: 4\n$ Station    &lt;chr&gt; \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\",…\n$ Date       &lt;date&gt; 2020-01-16, 2020-01-22, 2020-02-14, 2020-02-20, 2020-03-03…\n$ Chla       &lt;dbl&gt; 0.64, 0.67, 1.46, 2.15, 1.40, 1.89, 4.73, 1.74, 6.40, 2.79,…\n$ Pheophytin &lt;dbl&gt; 0.50, 0.87, 0.69, 0.50, 0.56, 1.13, 1.25, 0.89, 0.88, 0.85,…\n\n\n\n6.1.1 Aside: Tidyverse Pipes\nYou’ll notice I used some new syntax there, namely, the %&gt;%. This is called the pipe operator, Operators are functions that allows one to perform operations on other functions/variables. The pipe operator specifically allows you to chain together tidyverse commands.\nTherefore, instead of writing the above code like this:\n\nselect(df_wq, Station:Pheophytin)\n\n# A tibble: 62 × 4\n   Station Date        Chla Pheophytin\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 P8      2020-01-16  0.64       0.5 \n 2 D7      2020-01-22  0.67       0.87\n 3 P8      2020-02-14  1.46       0.69\n 4 D7      2020-02-20  2.15       0.5 \n 5 P8      2020-03-03  1.4        0.56\n 6 D7      2020-03-06  1.89       1.13\n 7 P8      2020-06-11  4.73       1.25\n 8 D7      2020-06-17  1.74       0.89\n 9 P8      2020-07-13  6.4        0.88\n10 D7      2020-07-16  2.79       0.85\n# ℹ 52 more rows\n\n\nFor clarity, I can pipe the dataframe into the select function:\n\ndf_wq %&gt;% select(Station:Pheophytin)\n\n# A tibble: 62 × 4\n   Station Date        Chla Pheophytin\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 P8      2020-01-16  0.64       0.5 \n 2 D7      2020-01-22  0.67       0.87\n 3 P8      2020-02-14  1.46       0.69\n 4 D7      2020-02-20  2.15       0.5 \n 5 P8      2020-03-03  1.4        0.56\n 6 D7      2020-03-06  1.89       1.13\n 7 P8      2020-06-11  4.73       1.25\n 8 D7      2020-06-17  1.74       0.89\n 9 P8      2020-07-13  6.4        0.88\n10 D7      2020-07-16  2.79       0.85\n# ℹ 52 more rows",
    "crumbs": [
      "Day 2: 7/11/2024",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulation</span>"
    ]
  },
  {
    "objectID": "code/Day2_DataOrg.html#subset-by-row-values",
    "href": "code/Day2_DataOrg.html#subset-by-row-values",
    "title": "\n3  Data Manipulation\n",
    "section": "\n6.2 Subset By Row Values",
    "text": "6.2 Subset By Row Values\nAnother common goal is to subset by particular row values – say, only a given station, date range, or analyte value range. Tidyverse also has functions for this! Specifically, we use filter from the dplyr package:\n\ndf_p8 &lt;- df_wq %&gt;% filter(Station == 'P8')\n\n\nunique(df_p8$Station)\n\n[1] \"P8\"",
    "crumbs": [
      "Day 2: 7/11/2024",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulation</span>"
    ]
  },
  {
    "objectID": "code/Day2_DataOrg.html#aside-logical-operators",
    "href": "code/Day2_DataOrg.html#aside-logical-operators",
    "title": "\n3  Data Manipulation\n",
    "section": "\n6.3 Aside: Logical Operators",
    "text": "6.3 Aside: Logical Operators\n\n6.3.1 equality (==) and negate equality (!=)\nNote we used another new symbol: ==. This is the equality operator, a type of logical operator. Logical operators allow us to dictate what our code does via logical statements.\nEquality, as we saw above, tells the code to find all values from the right-hand side that are equal to the left-hand side.\nNegate does the opposite; it gives us the values that do not match. Here, we apply it to the equality operator, but note that ! is the general negate operator; it can be applied to any logical statement.\n\ndf_notp8 &lt;- df_wq %&gt;% filter(Station != 'P8')\n\n\nunique(df_notp8$Station)\n\n[1] \"D7\"\n\n\n\n6.3.2 and (&) and or (|)\nSometimes, we want to filter by multiple commands at once. We can use this using the logical operators and (&) or or (’|`):\n\ndf_wq %&gt;% filter(Station == 'P8' & Date == '2020-01-16')\n\n# A tibble: 1 × 20\n  Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 P8      2020-01-16  0.64        0.5            98        0.15\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\ndf_wq %&gt;% filter(Date == '2020-01-16' | Date == '2020-01-22')\n\n# A tibble: 2 × 20\n  Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 P8      2020-01-16  0.64       0.5             98        0.15\n2 D7      2020-01-22  0.67       0.87            82        0.21\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\n6.3.3 less than &lt; and greater than &gt;\n\nSometimes, we want all values above or below:\n\ndf_wq %&gt;% filter(Date &gt;= '2020-02-01')\n\n# A tibble: 60 × 20\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2020-02-14  1.46       0.69            81        0.25\n 2 D7      2020-02-20  2.15       0.5             86        0.14\n 3 P8      2020-03-03  1.4        0.56            80        0.11\n 4 D7      2020-03-06  1.89       1.13            93        0.22\n 5 P8      2020-06-11  4.73       1.25            59        0.05\n 6 D7      2020-06-17  1.74       0.89            78        0.05\n 7 P8      2020-07-13  6.4        0.88            63        0.05\n 8 D7      2020-07-16  2.79       0.85            80        0.05\n 9 P8      2020-08-11 16.5        1.41            65        0.05\n10 D7      2020-08-17  0.5        6.13            83        0.05\n# ℹ 50 more rows\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\ndf_wq %&gt;% filter(Date &lt;= '2020-06-30')\n\n# A tibble: 8 × 20\n  Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 P8      2020-01-16  0.64       0.5             98        0.15\n2 D7      2020-01-22  0.67       0.87            82        0.21\n3 P8      2020-02-14  1.46       0.69            81        0.25\n4 D7      2020-02-20  2.15       0.5             86        0.14\n5 P8      2020-03-03  1.4        0.56            80        0.11\n6 D7      2020-03-06  1.89       1.13            93        0.22\n7 P8      2020-06-11  4.73       1.25            59        0.05\n8 D7      2020-06-17  1.74       0.89            78        0.05\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\ndf_wq %&gt;% filter(!(Date &gt;= '2020-06-30')) # same thing but using negate\n\n# A tibble: 8 × 20\n  Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 P8      2020-01-16  0.64       0.5             98        0.15\n2 D7      2020-01-22  0.67       0.87            82        0.21\n3 P8      2020-02-14  1.46       0.69            81        0.25\n4 D7      2020-02-20  2.15       0.5             86        0.14\n5 P8      2020-03-03  1.4        0.56            80        0.11\n6 D7      2020-03-06  1.89       1.13            93        0.22\n7 P8      2020-06-11  4.73       1.25            59        0.05\n8 D7      2020-06-17  1.74       0.89            78        0.05\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\nWhat if we want data in between two dates? We can use the and (&) operator!\n\ndf_wq %&gt;% filter(Date &gt;= '2020-02-01' & Date &lt;= '2020-06-30')\n\n# A tibble: 6 × 20\n  Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 P8      2020-02-14  1.46       0.69            81        0.25\n2 D7      2020-02-20  2.15       0.5             86        0.14\n3 P8      2020-03-03  1.4        0.56            80        0.11\n4 D7      2020-03-06  1.89       1.13            93        0.22\n5 P8      2020-06-11  4.73       1.25            59        0.05\n6 D7      2020-06-17  1.74       0.89            78        0.05\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\n6.3.4 in (%in%)\nWhat if we wanted to subset by five specific dates? We could string together multiple or (|) commands, but that can become unwieldy to write.\nWhat if I instead had a vector of those five specific dates? Then I could subset by all the data in my dataset that matches one of the values in that vector.\nThis is what the %in% function does:\n\ndf_wq %&gt;% filter(Date %in% c('2020-02-14','2020-03-06','2020-06-11','2021-03-05','2021-04-05'))\n\n# A tibble: 5 × 20\n  Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 P8      2020-02-14  1.46       0.69            81       0.25 \n2 D7      2020-03-06  1.89       1.13            93       0.22 \n3 P8      2020-06-11  4.73       1.25            59       0.05 \n4 P8      2021-03-05  1.56       0.5            103       0.299\n5 P8      2021-04-05  2.62       1.1            116       0.063\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\n6.3.5 Aside: the lubridate package\nWhat if I want to subset all values in a given year? If I had a vector of all the years in my dataset, then I could simply use %in%! But how would I get that vector?\nThe lubridate package allows you to manipulate dates. Since dates are complicated in R, we won’t go into too much detail. However, a few useful functions are day, month, and year, which returns the days, months, and years (as vectors) from a vector of dates:\nOriginal:\n\ndf_wq$Date\n\n [1] \"2020-01-16\" \"2020-01-22\" \"2020-02-14\" \"2020-02-20\" \"2020-03-03\"\n [6] \"2020-03-06\" \"2020-06-11\" \"2020-06-17\" \"2020-07-13\" \"2020-07-16\"\n[11] \"2020-08-11\" \"2020-08-17\" \"2020-09-09\" \"2020-09-24\" \"2020-10-08\"\n[16] \"2020-10-13\" \"2020-11-06\" \"2020-11-12\" \"2021-03-05\" \"2021-03-10\"\n[21] \"2021-04-05\" \"2021-04-08\" \"2021-05-05\" \"2021-05-10\" \"2021-06-03\"\n[26] \"2021-06-08\" \"2021-07-16\" \"2021-07-21\" \"2021-08-16\" \"2021-08-19\"\n[31] \"2021-09-10\" \"2021-09-16\" \"2021-10-13\" \"2021-10-18\" \"2021-11-10\"\n[36] \"2021-11-16\" \"2021-12-10\" \"2021-12-15\" \"2022-01-12\" \"2022-02-14\"\n[41] \"2022-03-16\" \"2022-04-27\" \"2022-05-27\" \"2022-06-27\" \"2022-07-25\"\n[46] \"2022-08-22\" \"2022-09-20\" \"2022-10-19\" \"2022-11-18\" \"2022-12-19\"\n[51] \"2022-01-07\" \"2022-02-09\" \"2022-03-11\" \"2022-04-22\" \"2022-05-23\"\n[56] \"2022-06-22\" \"2022-07-20\" \"2022-08-17\" \"2022-09-15\" \"2022-10-14\"\n[61] \"2022-11-15\" \"2022-12-14\"\n\n\nDays:\n\nday(df_wq$Date)\n\n [1] 16 22 14 20  3  6 11 17 13 16 11 17  9 24  8 13  6 12  5 10  5  8  5 10  3\n[26]  8 16 21 16 19 10 16 13 18 10 16 10 15 12 14 16 27 27 27 25 22 20 19 18 19\n[51]  7  9 11 22 23 22 20 17 15 14 15 14\n\n\nMonths:\n\nmonth(df_wq$Date)\n\n [1]  1  1  2  2  3  3  6  6  7  7  8  8  9  9 10 10 11 11  3  3  4  4  5  5  6\n[26]  6  7  7  8  8  9  9 10 10 11 11 12 12  1  2  3  4  5  6  7  8  9 10 11 12\n[51]  1  2  3  4  5  6  7  8  9 10 11 12\n\n\nYears:\n\nyear(df_wq$Date)\n\n [1] 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020\n[16] 2020 2020 2020 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021\n[31] 2021 2021 2021 2021 2021 2021 2021 2021 2022 2022 2022 2022 2022 2022 2022\n[46] 2022 2022 2022 2022 2022 2022 2022 2022 2022 2022 2022 2022 2022 2022 2022\n[61] 2022 2022\n\n\nOne use for these functions is subsetting! Say we want all entries from the year 2021:\n\ndf_wq %&gt;% filter(year(Date) %in% '2021')\n\n# A tibble: 20 × 20\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2021-03-05  1.56       0.5          103         0.299\n 2 D7      2021-03-10  4.77       0.5           97.9       0.135\n 3 P8      2021-04-05  2.62       1.1          116         0.063\n 4 D7      2021-04-08  3.28       0.83          93.9       0.078\n 5 P8      2021-05-05  4.73       1.48          89.9       0.05 \n 6 D7      2021-05-10  1.85       0.55         100         0.093\n 7 P8      2021-06-03  4.39       0.5           78.1       0.056\n 8 D7      2021-06-08  4.21       1.2           96.8       0.058\n 9 P8      2021-07-16  4.3        2.28          49.2       0.05 \n10 D7      2021-07-21  6.54       1.15          93.4       0.05 \n11 P8      2021-08-16  5.56       1.2           46.4       0.05 \n12 D7      2021-08-19  6.76       4.03          91.1       0.05 \n13 P8      2021-09-10  3.85       1.22          57.5       0.069\n14 D7      2021-09-16  2.74       1.32          91.5       0.05 \n15 P8      2021-10-13  1.97       0.57          74.9       0.069\n16 D7      2021-10-18  2.95       2.86          94.9       0.073\n17 P8      2021-11-10  1.25       0.92          59.8       0.118\n18 D7      2021-11-16  1.52       1.38          85.6       0.186\n19 P8      2021-12-10  1.52       0.7           79.4       0.09 \n20 D7      2021-12-15  1.17       1.55          91.5       0.192\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\n# same thing but using negate\ndf_wq %&gt;% filter(\n  !(year(Date) %in% c('2020','2022'))\n  )\n\n# A tibble: 20 × 20\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2021-03-05  1.56       0.5          103         0.299\n 2 D7      2021-03-10  4.77       0.5           97.9       0.135\n 3 P8      2021-04-05  2.62       1.1          116         0.063\n 4 D7      2021-04-08  3.28       0.83          93.9       0.078\n 5 P8      2021-05-05  4.73       1.48          89.9       0.05 \n 6 D7      2021-05-10  1.85       0.55         100         0.093\n 7 P8      2021-06-03  4.39       0.5           78.1       0.056\n 8 D7      2021-06-08  4.21       1.2           96.8       0.058\n 9 P8      2021-07-16  4.3        2.28          49.2       0.05 \n10 D7      2021-07-21  6.54       1.15          93.4       0.05 \n11 P8      2021-08-16  5.56       1.2           46.4       0.05 \n12 D7      2021-08-19  6.76       4.03          91.1       0.05 \n13 P8      2021-09-10  3.85       1.22          57.5       0.069\n14 D7      2021-09-16  2.74       1.32          91.5       0.05 \n15 P8      2021-10-13  1.97       0.57          74.9       0.069\n16 D7      2021-10-18  2.95       2.86          94.9       0.073\n17 P8      2021-11-10  1.25       0.92          59.8       0.118\n18 D7      2021-11-16  1.52       1.38          85.6       0.186\n19 P8      2021-12-10  1.52       0.7           79.4       0.09 \n20 D7      2021-12-15  1.17       1.55          91.5       0.192\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\n6.3.6 Exercise\nIn one filter function, how would I select data that’s either before 2020-02-28 or after 2022-11-01?\n\nCodedf_wq %&gt;% filter(Date &lt;= '2020-02-28' | Date &gt;= '2022-11-01')",
    "crumbs": [
      "Day 2: 7/11/2024",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulation</span>"
    ]
  },
  {
    "objectID": "code/Day2_DataOrg.html#subset-by-column-and-row",
    "href": "code/Day2_DataOrg.html#subset-by-column-and-row",
    "title": "\n3  Data Manipulation\n",
    "section": "\n6.4 Subset by Column and Row",
    "text": "6.4 Subset by Column and Row\nUsing our knowledge of pipes, it’s easy to subset by column and row at the same time!\n\ndf_wq %&gt;% filter(Date == '2020-01-16' | Date == '2020-01-22') %&gt;% select(Station:Pheophytin)\n\n# A tibble: 2 × 4\n  Station Date        Chla Pheophytin\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 P8      2020-01-16  0.64       0.5 \n2 D7      2020-01-22  0.67       0.87\n\n\n\n6.4.1 Aside: Formatting Code\nNotice that above all the code is on the same line. This can be difficult to read. You can get around this by formatting your code. Personally, I like having different functions on different lines:\n\ndf_wq %&gt;%\n  filter(Date == '2020-01-16' | Date == '2020-01-22') %&gt;%\n  select(Station:Pheophytin)\n\n# A tibble: 2 × 4\n  Station Date        Chla Pheophytin\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 P8      2020-01-16  0.64       0.5 \n2 D7      2020-01-22  0.67       0.87\n\n\nYou can also use ctrl+shift+A to auto-format code! Note that it looks different from above; this is fine. As long as you deem the code readable (and it works), you’re set.\n\n# original\ndf_wq %&gt;% filter(Date == '2020-01-16' | Date == '2020-01-22') %&gt;% select(Station:Pheophytin)\n\n# A tibble: 2 × 4\n  Station Date        Chla Pheophytin\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 P8      2020-01-16  0.64       0.5 \n2 D7      2020-01-22  0.67       0.87\n\n# ctrl+shift+A\ndf_wq %&gt;% filter(Date == '2020-01-16' |\n                   Date == '2020-01-22') %&gt;% select(Station:Pheophytin)\n\n# A tibble: 2 × 4\n  Station Date        Chla Pheophytin\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 P8      2020-01-16  0.64       0.5 \n2 D7      2020-01-22  0.67       0.87",
    "crumbs": [
      "Day 2: 7/11/2024",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulation</span>"
    ]
  },
  {
    "objectID": "code/Day2_DataOrg.html#subset-na",
    "href": "code/Day2_DataOrg.html#subset-na",
    "title": "\n3  Data Manipulation\n",
    "section": "\n6.5 Subset NA",
    "text": "6.5 Subset NA\nThere’s one more type of subset that we’ll cover today. This is selecting data that is NA.\nNA is a logical constant of length 1 which contains a missing value indicator:\n\ntypeof(NA) # NA\n\n[1] \"logical\"\n\ntypeof('NA') # not the same\n\n[1] \"character\"\n\n\nSometimes, we want to select only NA data, or omit it entirely. Looking at the Chla column, we see that there are NAs:\n\nunique(df_wq$DON)\n\n [1]   NA 0.30 0.20 0.10 0.50 0.22 0.19 0.11 0.53 0.13 0.46 0.25 0.37 0.29 0.17\n[16] 0.24 0.27 0.21 0.35 0.12 0.18 0.16 1.07 0.33 0.40 0.44 0.43 0.42 0.38\n\n\nA quicker to check this is the is.na function:\n\nis.na(df_wq$DON)\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[61] FALSE FALSE\n\n\nThis returns a logical vector. If I want to subset by this, I can use the filter function:\n\ndf_wq %&gt;%\n  filter(is.na(df_wq$DON)) %&gt;%\n  select(Station, Date, DON)\n\n# A tibble: 6 × 3\n  Station Date         DON\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;\n1 P8      2020-01-16    NA\n2 D7      2020-01-22    NA\n3 P8      2020-02-14    NA\n4 D7      2020-02-20    NA\n5 P8      2020-03-03    NA\n6 D7      2020-03-06    NA\n\n\nQuestion: What operator would I use if I want all data except NAs (hint: I want to negate NA)\nChallenge Exercise: How would I write this statement? (Hint: examples are above)\n\nCodedf_wq %&gt;%\n  filter(!is.na(df_wq$DON)) %&gt;% # use the ! operator before the function to negate it\n  select(Station, Date, DON)",
    "crumbs": [
      "Day 2: 7/11/2024",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulation</span>"
    ]
  },
  {
    "objectID": "code/Day2_DataOrg.html#new-columns",
    "href": "code/Day2_DataOrg.html#new-columns",
    "title": "\n3  Data Manipulation\n",
    "section": "\n7.1 New Columns",
    "text": "7.1 New Columns\nSometimes, we want to modify our already existing columns, or even add new ones. This is where the mutate function from the dplyr package comes in.\nWith mutate, we can add in new columns:\n\nhead(df_notp8)\n\n# A tibble: 6 × 20\n  Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 D7      2020-01-22  0.67       0.87            82        0.21\n2 D7      2020-02-20  2.15       0.5             86        0.14\n3 D7      2020-03-06  1.89       1.13            93        0.22\n4 D7      2020-06-17  1.74       0.89            78        0.05\n5 D7      2020-07-16  2.79       0.85            80        0.05\n6 D7      2020-08-17  0.5        6.13            83        0.05\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\ndf_wq %&gt;%\n  mutate(Lab = 'BSA')\n\n# A tibble: 62 × 21\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2020-01-16  0.64       0.5             98        0.15\n 2 D7      2020-01-22  0.67       0.87            82        0.21\n 3 P8      2020-02-14  1.46       0.69            81        0.25\n 4 D7      2020-02-20  2.15       0.5             86        0.14\n 5 P8      2020-03-03  1.4        0.56            80        0.11\n 6 D7      2020-03-06  1.89       1.13            93        0.22\n 7 P8      2020-06-11  4.73       1.25            59        0.05\n 8 D7      2020-06-17  1.74       0.89            78        0.05\n 9 P8      2020-07-13  6.4        0.88            63        0.05\n10 D7      2020-07-16  2.79       0.85            80        0.05\n# ℹ 52 more rows\n# ℹ 15 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;, Lab &lt;chr&gt;\n\n\nWe can even add columns that are combinations of other ones:\n\ndf_wq %&gt;%\n  mutate(chlpheo = Chla+Pheophytin)\n\n# A tibble: 62 × 21\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2020-01-16  0.64       0.5             98        0.15\n 2 D7      2020-01-22  0.67       0.87            82        0.21\n 3 P8      2020-02-14  1.46       0.69            81        0.25\n 4 D7      2020-02-20  2.15       0.5             86        0.14\n 5 P8      2020-03-03  1.4        0.56            80        0.11\n 6 D7      2020-03-06  1.89       1.13            93        0.22\n 7 P8      2020-06-11  4.73       1.25            59        0.05\n 8 D7      2020-06-17  1.74       0.89            78        0.05\n 9 P8      2020-07-13  6.4        0.88            63        0.05\n10 D7      2020-07-16  2.79       0.85            80        0.05\n# ℹ 52 more rows\n# ℹ 15 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;, chlpheo &lt;dbl&gt;\n\n\n\ndf_wq %&gt;%\n  mutate(statdate = paste(Station,Date,sep = '_'))\n\n# A tibble: 62 × 21\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2020-01-16  0.64       0.5             98        0.15\n 2 D7      2020-01-22  0.67       0.87            82        0.21\n 3 P8      2020-02-14  1.46       0.69            81        0.25\n 4 D7      2020-02-20  2.15       0.5             86        0.14\n 5 P8      2020-03-03  1.4        0.56            80        0.11\n 6 D7      2020-03-06  1.89       1.13            93        0.22\n 7 P8      2020-06-11  4.73       1.25            59        0.05\n 8 D7      2020-06-17  1.74       0.89            78        0.05\n 9 P8      2020-07-13  6.4        0.88            63        0.05\n10 D7      2020-07-16  2.79       0.85            80        0.05\n# ℹ 52 more rows\n# ℹ 15 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;, statdate &lt;chr&gt;\n\n\n\n7.1.1 Aside: Relocate Columns\nSometimes, we want to re-arrange our column order. For example, with our new Lab column, we might want that in the beginning with the other metadata. Here, we use the relocate function:\n\ndf_wq %&gt;%\n  mutate(Lab = 'BSA') %&gt;%\n  relocate(Lab, .after = Date)\n\n# A tibble: 62 × 21\n   Station Date       Lab    Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2020-01-16 BSA    0.64       0.5             98        0.15\n 2 D7      2020-01-22 BSA    0.67       0.87            82        0.21\n 3 P8      2020-02-14 BSA    1.46       0.69            81        0.25\n 4 D7      2020-02-20 BSA    2.15       0.5             86        0.14\n 5 P8      2020-03-03 BSA    1.4        0.56            80        0.11\n 6 D7      2020-03-06 BSA    1.89       1.13            93        0.22\n 7 P8      2020-06-11 BSA    4.73       1.25            59        0.05\n 8 D7      2020-06-17 BSA    1.74       0.89            78        0.05\n 9 P8      2020-07-13 BSA    6.4        0.88            63        0.05\n10 D7      2020-07-16 BSA    2.79       0.85            80        0.05\n# ℹ 52 more rows\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;",
    "crumbs": [
      "Day 2: 7/11/2024",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulation</span>"
    ]
  },
  {
    "objectID": "code/Day2_DataOrg.html#existing-columns",
    "href": "code/Day2_DataOrg.html#existing-columns",
    "title": "\n3  Data Manipulation\n",
    "section": "\n7.2 Existing Columns",
    "text": "7.2 Existing Columns\nWe can also use mutate to modify existing columns\n\ndf_wq %&gt;%\n  mutate(Chla = Chla+20)\n\n# A tibble: 62 × 20\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2020-01-16  20.6       0.5             98        0.15\n 2 D7      2020-01-22  20.7       0.87            82        0.21\n 3 P8      2020-02-14  21.5       0.69            81        0.25\n 4 D7      2020-02-20  22.2       0.5             86        0.14\n 5 P8      2020-03-03  21.4       0.56            80        0.11\n 6 D7      2020-03-06  21.9       1.13            93        0.22\n 7 P8      2020-06-11  24.7       1.25            59        0.05\n 8 D7      2020-06-17  21.7       0.89            78        0.05\n 9 P8      2020-07-13  26.4       0.88            63        0.05\n10 D7      2020-07-16  22.8       0.85            80        0.05\n# ℹ 52 more rows\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\nWe can even change types! This is useful if, say, you have character column that should be numeric.\n\ndf_wq %&gt;%\n  mutate(Chla = as.numeric(Chla),\n         Pheophytin = as.numeric(Pheophytin))\n\n# A tibble: 62 × 20\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2020-01-16  0.64       0.5             98        0.15\n 2 D7      2020-01-22  0.67       0.87            82        0.21\n 3 P8      2020-02-14  1.46       0.69            81        0.25\n 4 D7      2020-02-20  2.15       0.5             86        0.14\n 5 P8      2020-03-03  1.4        0.56            80        0.11\n 6 D7      2020-03-06  1.89       1.13            93        0.22\n 7 P8      2020-06-11  4.73       1.25            59        0.05\n 8 D7      2020-06-17  1.74       0.89            78        0.05\n 9 P8      2020-07-13  6.4        0.88            63        0.05\n10 D7      2020-07-16  2.79       0.85            80        0.05\n# ℹ 52 more rows\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\n7.2.1 Aside: Case When\nWhat if we only want to modify certain data in a column? Say, we want to add 20 to all Chla values but only for P8.\nThis can be done using the case_when function instead a mutate function:\n\ndf_wq %&gt;%\n  mutate(\n    Chla =\n      case_when(Station == 'P8' ~ Chla + 20, # if station is P8, add 20\n              TRUE ~ Chla) # else, keeep as previous value\n  ) %&gt;%\n  select(c(Station:Date), Chla)\n\n# A tibble: 62 × 3\n   Station Date        Chla\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;\n 1 P8      2020-01-16 20.6 \n 2 D7      2020-01-22  0.67\n 3 P8      2020-02-14 21.5 \n 4 D7      2020-02-20  2.15\n 5 P8      2020-03-03 21.4 \n 6 D7      2020-03-06  1.89\n 7 P8      2020-06-11 24.7 \n 8 D7      2020-06-17  1.74\n 9 P8      2020-07-13 26.4 \n10 D7      2020-07-16  2.79\n# ℹ 52 more rows",
    "crumbs": [
      "Day 2: 7/11/2024",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulation</span>"
    ]
  },
  {
    "objectID": "code/Day3_MakingGraphs.html",
    "href": "code/Day3_MakingGraphs.html",
    "title": "\n4  Making Graphs\n",
    "section": "",
    "text": "4.1 Making Graphs in R\nOne of the greatest strengths of R is its ability to produce a wide variety of professional quality custom graphs. Today, we will cover the basics of visualizing data using the popular ggplot2 package. We will cover a broad range of basic graphs that are useful for visualizing water quality and biological data.",
    "crumbs": [
      "Day 3: 7/16/2024",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Making Graphs</span>"
    ]
  },
  {
    "objectID": "code/Day3_MakingGraphs.html#making-graphs-in-r",
    "href": "code/Day3_MakingGraphs.html#making-graphs-in-r",
    "title": "\n4  Making Graphs\n",
    "section": "",
    "text": "4.1.1 A note on base R graphics\nWhen you download R, there is a suite of packages that are included. These packages include functions for carrying out a variety of basic tasks, including making graphs. I used base R graphing functions for a number of years, and there’s nothing wrong with using these functions. However, in more recent years, I have completely switched to using the ggplot2 package and think it is a great package for new R users to know.\n\n4.1.2 Continuous vs categorical data\nAs we decide what type of plot to make, it is useful to consider the types of data we are plotting. Continuous data refers to numbers like water temperature. Categorical refers to types within a group (e.g., station).",
    "crumbs": [
      "Day 3: 7/16/2024",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Making Graphs</span>"
    ]
  },
  {
    "objectID": "code/Day3_MakingGraphs.html#set-up",
    "href": "code/Day3_MakingGraphs.html#set-up",
    "title": "\n4  Making Graphs\n",
    "section": "\n4.2 Set up",
    "text": "4.2 Set up\n\n4.2.1 Load the required R packages\nSo without further ado, let’s load the packages we need for today’s tutorial. We will load the tidyverse because it included ggplot2 and a variety of other useful packages. We will also load here to simplify reading and writing files.\nI will briefly show some features of the viridis and patchwork packages, but you don’t need to worry about downloading them yourself right now.\n\nlibrary(tidyverse) #suite of data science tools\nlibrary(here) #setting working directory\nlibrary(viridis) #color blind friendly color palettes\nlibrary(patchwork) #combining plots into panels\n\n\n4.2.2 Read in the dataset\nWe will continue to use the same EMP water quality data set that you used for the first two parts of this course.\n\nwqdata &lt;- read_csv( here(\"data/WQ_P8D7.csv\"))\n\n\n4.2.3 Look at at the data set\nLet’s take a quick look at the structure of the data to remind ourselves of the column names and data types in this data set\n\nglimpse(wqdata)\n\nRows: 62\nColumns: 20\n$ Station            &lt;chr&gt; \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8…\n$ Date               &lt;date&gt; 2020-01-16, 2020-01-22, 2020-02-14, 2020-02-20, 20…\n$ Chla               &lt;dbl&gt; 0.64, 0.67, 1.46, 2.15, 1.40, 1.89, 4.73, 1.74, 6.4…\n$ Pheophytin         &lt;dbl&gt; 0.50, 0.87, 0.69, 0.50, 0.56, 1.13, 1.25, 0.89, 0.8…\n$ TotAlkalinity      &lt;dbl&gt; 98.0, 82.0, 81.0, 86.0, 80.0, 93.0, 59.0, 78.0, 63.…\n$ DissAmmonia        &lt;dbl&gt; 0.150, 0.210, 0.250, 0.140, 0.110, 0.220, 0.050, 0.…\n$ DissNitrateNitrite &lt;dbl&gt; 2.800, 0.490, 1.700, 0.480, 1.600, 0.380, 1.070, 0.…\n$ DOC                &lt;dbl&gt; 3.90, 0.27, 2.80, 0.39, 2.00, 0.19, 2.80, 1.20, 3.1…\n$ TOC                &lt;dbl&gt; 4.10, 0.32, 2.50, 0.41, 2.10, 0.20, 2.80, 1.20, 3.1…\n$ DON                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 0.30, 0.20, 0.30, 0.10, 0.5…\n$ TotPhos            &lt;dbl&gt; 0.310, 0.082, 0.130, 0.130, 0.190, 0.100, 0.188, 0.…\n$ DissOrthophos      &lt;dbl&gt; 0.200, 0.071, 0.130, 0.065, 0.140, 0.082, 0.177, 0.…\n$ TDS                &lt;dbl&gt; 380, 9500, 340, 5800, 290, 8700, 280, 7760, 227, 11…\n$ TSS                &lt;dbl&gt; 8.9, 38.0, 2.2, 18.0, 1.4, 28.0, 6.6, 35.6, 5.3, 23…\n$ TKN                &lt;dbl&gt; 0.520, 0.480, 0.430, 0.250, 0.400, 0.200, 0.400, 0.…\n$ Depth              &lt;dbl&gt; 28.9, 18.8, 39.0, 7.1, 39.0, 7.2, 37.1, 5.2, 36.7, …\n$ Secchi             &lt;dbl&gt; 116, 30, 212, 52, 340, 48, 100, 40, 160, 44, 120, 6…\n$ Microcystis        &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 3, 2, 3, 2, 4, 2, 3, 2, 2, 1, 1, …\n$ SpCndSurface       &lt;dbl&gt; 667, 15532, 647, 11369, 530, 16257, 503, 12946, 404…\n$ WTSurface          &lt;dbl&gt; 9.67, 9.97, 11.09, 12.51, 13.97, 13.81, 23.46, 21.1…\n\n\nAside from staton, everything is “dbl” or “double”, which just means they are considered numeric data.",
    "crumbs": [
      "Day 3: 7/16/2024",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Making Graphs</span>"
    ]
  },
  {
    "objectID": "code/Day3_MakingGraphs.html#lets-make-graphs",
    "href": "code/Day3_MakingGraphs.html#lets-make-graphs",
    "title": "\n4  Making Graphs\n",
    "section": "\n4.3 Let’s make graphs!",
    "text": "4.3 Let’s make graphs!\nThe ggplot2 package utilizes the grammar of graphics and creates plots in “layers”. We will learn about some of the core “geometries”, which specify how the graph will look (e.g., bar plot vs line plot).\n\n4.3.1 Histograms\nLet’s start making plots, so we can learn the anatomy of the ggplot() function. We will begin with a histogram, which simply shows the distribution of data for a single variable. Histograms can be used to show the number of observations for each category (bin) of a categorical variable or the number of observations of a continuous variable within each number range (bin). We will plot surface water temperature (WTSurface).\nWithin the ggplot() function, the first thing we should do is specify the data set we want to plot using the data argument. Then, we will indicate which column within the data set we want to plot. These are the most basic components.\nFrom here, we use the + sign to add layers upon the foundation we have built. In this case, we want a histogram, so we use the argument geom_histogram(). There are many types of graphs you can make and ggplot has similarly named arguments for each of them (e.g., geom_point, geom_line). We will look at more of these shortly.\n\n(plot_hist_temp &lt;- ggplot(data = wqdata, aes(x = WTSurface)) +\n  geom_histogram()\n)\n\n\n\n\n\n\n\nThe default number of bins do not work very well. We can make some manual adjustments within the geom_histogram() argument. Let’s try eight bins.\n\n(plot_hist_temp_bins &lt;- ggplot(data = wqdata, aes(x = WTSurface)) +\n  geom_histogram(bins = 8)\n)\n\n\n\n\n\n\n\n\n4.3.1.1 Your Turn\nBased on the code above for the water temperature histogram, make a histogram of surface specific conductance (SpCndSurface) and try different numbers of bins.\n\nCode(plot_hist_sc &lt;- ggplot(data = wqdata, aes(x = SpCndSurface)) +\n   geom_histogram(bins = 6)\n)\n\n\nIf we had plotted data for a single station, the histogram would be roughly bell shaped, but because we are plotting data for two stations in different parts of the salinity gradient, we get a bimodal distribution.",
    "crumbs": [
      "Day 3: 7/16/2024",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Making Graphs</span>"
    ]
  },
  {
    "objectID": "code/Day3_MakingGraphs.html#time-series-plots",
    "href": "code/Day3_MakingGraphs.html#time-series-plots",
    "title": "\n4  Making Graphs\n",
    "section": "\n4.4 Time series plots",
    "text": "4.4 Time series plots\nNext, let’s plot a time series of data. These plots are helpful for looking at monitoring data through time to identify patterns or for looking for outliers. For a histogram, there was only an x variable. For most types of plots, including time series plots, there are x and y variables to specify.\nWe will plot a year of Secchi depth data to see how it changes through the seasons. As a reminder, higher Secchi depth means lower turbidity.\nFor simplicity, we will just plot the data for one station, P8. Each value for Secchi will be plotted as a point, so we will use geom_point().\n\n#filter data set to only data for station P8\nwqdata_p8 &lt;- wqdata %&gt;% \n  filter(Station == \"P8\") \n\n#filter data set to only data for station D7\n#we will use this a little later\nwqdata_d7 &lt;- wqdata %&gt;% \n  filter(Station == \"D7\") \n\n#now plot this subset of the data\n(plot_ts_points &lt;- ggplot(data = wqdata_p8, aes(x = Date, y = Secchi)) +\n  geom_point()\n)\n\n\n\n\n\n\n\n\n#you can also do the filtering and plotting all at once if you want\n(plot_ts_points2 &lt;- wqdata %&gt;% \n    filter(Station == \"P8\") %&gt;% \n      ggplot(aes(x = Date, y = Secchi)) +\n    geom_point()\n)\n\n\n\n\n\n\n\nWe can start to see how Secchi depth changed over time, but it would be easier with lines connecting the points. Let’s add some, which will highlight how ggplot works by building layers. As you might expect, we add the lines using geom_line().\n\n#time series plot with connecting lines\n(plot_ts_points_lines_p8 &lt;- ggplot(data = wqdata_p8, aes(x = Date, y = Secchi)) +\n  geom_point()+\n  geom_line())\n\n\n\n\n\n\n\nBecause we are simply building upon the previous graph made with only the points, we can also use this shortened approach, which further demonstrates that we are simply adding layers\n\n(plot_ts_points_lines_p8_2&lt;- plot_ts_points +\n  geom_line())\n\n\n\n\n\n\n\nNow it is a little easier to see the patterns through time. We can see that Secchi depth varies seasonally, generally with low values in rainy winter months and high values in dry summer months. Note there is a gap in the time series in 2021 to reflect a missing value.\n\n4.4.1 Your Turn\nMake a similar time series plot of Secchi depth for station D7. How does Secchi compare between the two stations?\n\nCode(plot_ts_points_lines_d7 &lt;- ggplot(data = wqdata_d7, aes(x = Date, y = Secchi)) +\n  geom_point()+\n  geom_line())\n\n\nSecchi depth is generally much lower at D7 than P8, indicating higher turbidity at D7.",
    "crumbs": [
      "Day 3: 7/16/2024",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Making Graphs</span>"
    ]
  },
  {
    "objectID": "code/Day3_MakingGraphs.html#multiple-time-series-per-plot",
    "href": "code/Day3_MakingGraphs.html#multiple-time-series-per-plot",
    "title": "\n4  Making Graphs\n",
    "section": "\n4.5 Multiple time series per plot",
    "text": "4.5 Multiple time series per plot\nWe can plot multiple time series on the same graph in order to more easily compare them. We will plot Secchi for P8 and D7 together. The ggplot() function will apply two different default colors to the two stations.\n\n#time series plot with connecting lines for both stations\n(plot_ts_points_lines_two &lt;- ggplot(data = wqdata, aes(x = Date, y = Secchi, group = Station)) +\n  geom_point(aes(color = Station))+\n  geom_line(aes(color = Station)))\n\n\n\n\n\n\n\nThis plot clearly shows what we noted above in the individual plots of Secchi depth, namely that Secchi depth is generally much higher at P8 than D7.",
    "crumbs": [
      "Day 3: 7/16/2024",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Making Graphs</span>"
    ]
  },
  {
    "objectID": "code/Day3_MakingGraphs.html#scatterplots",
    "href": "code/Day3_MakingGraphs.html#scatterplots",
    "title": "\n4  Making Graphs\n",
    "section": "\n4.6 Scatterplots",
    "text": "4.6 Scatterplots\nNext, let’s make a scatterplot. These plots are great for looking at relationships between pairs of continuous variables. As an example, we will plot dissolved organic carbon against total organic carbon. We will go back to using the dataset with both stations.\n\n(plot_scatter &lt;- ggplot(data = wqdata, aes(x = DOC, y = TOC)) +\n  geom_point()\n)\n\n\n\n\n\n\n\nThere appears to be a strong relationship between these two variables. Let’s add a trend line. As with the time series plot, we are building layers. However, we are not simply adding lines to connect the points, so we aren’t using geom_line(). To plot a trend line, we use geom_smooth(). There are various smooths that could be applied, so we need to specify what we want. In this case, we use a linear model (LM). By default, a 95% confidence interval (dark gray) is added around the trend line (blue).\n\n(plot_scatter_trend &lt;- plot_scatter +\n   geom_smooth(method = lm)\n   )\n\n\n\n\n\n\n\nOur focus today is making graphs rather than performing statistics, but I just wanted to show the correlation coefficient for this relationship.\n\ncor.test(wqdata$DOC,wqdata$TOC)\n\n\n    Pearson's product-moment correlation\n\ndata:  wqdata$DOC and wqdata$TOC\nt = 74.274, df = 60, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9910303 0.9967584\nsample estimates:\n      cor \n0.9946058 \n\n\nThe correlation is very strong between TOC and DOC (0.99). By convention, a correlation coefficient between 0.7 and 1.00 (the max) is considered a strong correlation.\n\n4.6.1 Your Turn\nPlot the relationship between Chla and Pheophytin and fit a line to it.\n\nCode(plot_scatter_trend_phyto &lt;- ggplot(data = wqdata, aes(x = Chla, y = Pheophytin)) +\n  geom_point()+\n  geom_smooth(method = lm)\n)\n\n\nThis does not look like much of a relationship. Let’s look at the correlation coefficient.\n\nCodecor.test(wqdata$Chla,wqdata$Pheophytin)\n\n\nThe correlation coefficient is -0.05, which indicates that Chla and Pheophytin are not significantly correlated. Even if we removed the outlier at high end of Chla, it would still not show a significant relationship.",
    "crumbs": [
      "Day 3: 7/16/2024",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Making Graphs</span>"
    ]
  },
  {
    "objectID": "code/Day3_MakingGraphs.html#box-and-whisker-plots",
    "href": "code/Day3_MakingGraphs.html#box-and-whisker-plots",
    "title": "\n4  Making Graphs\n",
    "section": "\n4.7 Box and whisker plots",
    "text": "4.7 Box and whisker plots\nIn scatter plots, we plot a continuous variable against another continuous variable. In some cases, we want to plot a continuous variable against a categorical variable. One type of plot that is useful in this situation is a box and whisker plot. These are great for initial data exploration and sometimes even in publications.\nMicrocystis abundance data is collected using a visual scoring system of 1 - 5, with 5 being the highest.\n\n\nMicrocystis ordinal scores\n\nMicrocystis blooms are associated with high water temperature. Let’s plot the Microcystis scores (categorical) against water temperature (continuous).\n\n(plot_bw1 &lt;- ggplot(data = wqdata, aes(x = Microcystis, y = WTSurface)) +\n   geom_boxplot()\n   )\n\nWarning: Continuous x aesthetic\nℹ did you forget `aes(group = ...)`?\n\n\n\n\n\n\n\n\nNote that Microcystis scores are ordered categories (i.e., ordinal), so R read them in as numeric data. If we try to make the plot with numeric Microcystis data, we don’t get the plot we expect. We will make this column a factor to indicate that these numbers are actually categories.\n\n(plot_bw2 &lt;- ggplot(data = wqdata, aes(x = factor(Microcystis), y = WTSurface)) +\n   geom_boxplot()\n   )\n\n\n\n\n\n\n\nThis is plot is what we were looking for, and it shows an increase in Microcystis with water temperature, like we anticipated. Note that scores of four are rare and scores of five are absent from the data set.\nPersonally, I like to include all the raw data points on the box and whisker plots because it gives folks an even better understanding of the distribution of the data. To do this, we add a layer with geom_jitter(). It is called this because the points are “jittered” to minimize overlap among them.\n\n(plot_bw_points &lt;- plot_bw2 +\n   geom_jitter()\n   )\n\n\n\n\n\n\n\n\n4.7.1 Your Turn\nMicrocystis needs a lot of light in addition to warm water. Plot Microcystis against Secchi depth to see whether turbidity is related to Microcystis abundance. Include the points for the raw data.\n\nCode(plot_bw_turb &lt;- ggplot(data = wqdata, aes(x = factor(Microcystis), y = Secchi)) +\n   geom_boxplot() +\n   geom_jitter()\n   )\n\n\nThe pattern is not as stark as for temperature, but we do see that Microcsystis scores are higher when Secchi depth is greater.",
    "crumbs": [
      "Day 3: 7/16/2024",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Making Graphs</span>"
    ]
  },
  {
    "objectID": "code/Day3_MakingGraphs.html#barplots",
    "href": "code/Day3_MakingGraphs.html#barplots",
    "title": "\n4  Making Graphs\n",
    "section": "\n4.8 Barplots",
    "text": "4.8 Barplots\nIn addition to box and whisker plots, you can make bar plots. Bar plots generally show less information than box and whisker plots, simply showing the means of a continuous variable by category.\nWe will make bar plots that are analogous to the box and whisker plots above. We will need to calculate some summary statistics (mean, standard deviation) for the continuous variables by Microcystis score before we can make the plots.\n\nwqdata_means &lt;- wqdata %&gt;% \n  group_by(Microcystis) %&gt;% \n  summarize(temp_mean = mean(WTSurface)\n            ,temp_sd = sd(WTSurface)\n            ,secchi_mean = mean(Secchi,na.rm = T)\n            ,secchi_sd = sd(Secchi,na.rm = T)\n            )\n\n(plot_bar &lt;- ggplot(data = wqdata_means, aes(x = factor(Microcystis), y = temp_mean)) +\n   geom_bar(stat = 'identity')\n   )\n\n\n\n\n\n\n\nHere’s another way to make the same plot.\n\n(plot_bar2 &lt;- ggplot(data = wqdata_means) +\n    geom_col(aes(x = factor(Microcystis), y = temp_mean))\n    )\n\n\n\n\n\n\n\nAdding error bars to bar plots provides more information about the distribution of the data, a bit like the whiskers in the box and whisker plots above. There are different options for types of error bars (e.g., standard deviation, standard error, 95% confidence interval). We will add error bars to our Microcystis plot based on standard deviation.\n\n(plot_bar_error &lt;- ggplot(data = wqdata_means, aes(x = factor(Microcystis), y = temp_mean)) +\n   geom_bar(stat = 'identity')+\n     geom_errorbar(aes(ymin = temp_mean-temp_sd, ymax = temp_mean+temp_sd),width = 0.2)\n   )\n\n\n\n\n\n\n\nWith the addition of error bars, we can see there is more variation in temperature for Microcystis score 1 than for Microcystis score 4.\n\n4.8.1 Your Turn\nMake bar plot of Microcystis scores vs Secchi depth. Include standard error bars. This is analogous to the box and whisker plot you made previously.\n\nCode(plot_bar_error_secchi &lt;- ggplot(data = wqdata_means, aes(x = factor(Microcystis), y = secchi_mean)) +\n   geom_bar(stat = 'identity')+\n     geom_errorbar(aes(ymin = secchi_mean-secchi_sd, ymax = secchi_mean+secchi_sd),width = 0.2)\n   )",
    "crumbs": [
      "Day 3: 7/16/2024",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Making Graphs</span>"
    ]
  },
  {
    "objectID": "code/Day3_MakingGraphs.html#stacked-bar-plot",
    "href": "code/Day3_MakingGraphs.html#stacked-bar-plot",
    "title": "\n4  Making Graphs\n",
    "section": "\n4.9 Stacked bar plot",
    "text": "4.9 Stacked bar plot\nSometimes we want a bar plot that simultaneously shows a total and its component parts at the same time, which is where stacked bar plots are useful.\nLet’s go back to the subset of data for Station P8. We might want to look at Dissolved Ammonium and Dissolved Nitrate and Nitrite through time together.\n\n#first we will rearrange the data frame a bit to make plotting easier\nwqdata_p8_nutrients &lt;- wqdata_p8 %&gt;% \n  #reduce data set down to just the needed columns\n  select(Station, Date, DissAmmonia, DissNitrateNitrite) %&gt;% \n  #convert from wide to long format\n  pivot_longer(cols = c(DissAmmonia,DissNitrateNitrite), names_to = \"Nutrient\", values_to = \"Value\")\n\n\n(plot_bar_stack_abs &lt;- ggplot(data = wqdata_p8_nutrients, aes(x = Date, y = Value, fill = Nutrient)) +\n   geom_bar(stat = 'identity')\n   )\n\n\n\n\n\n\n\nPerhaps we are more interested in the relative values rather than the absolute values. We just make a minor modification to the code above to accomplish this.\n\n(plot_bar_stack_rel &lt;- ggplot(data = wqdata_p8_nutrients, aes(x = Date, y = Value, fill = Nutrient)) +\n   geom_bar(stat = \"identity\", position = \"fill\")\n )\n\n\n\n\n\n\n\n\n4.9.1 Your Turn\nMake a stacked bar plot showing the relative amounts of ammonia and nitrate plus nitrite for D7 using the data set below (i.e., wqdata_d7_nutrients). How does the proportion of ammonia at D7 compare to that of P8?\n\nCodewqdata_d7_nutrients &lt;- wqdata_d7 %&gt;% \n  #reduce data set down to just the needed columns\n  select(Station, Date, DissAmmonia, DissNitrateNitrite) %&gt;% \n  #convert from wide to long format\n  pivot_longer(cols = c(DissAmmonia,DissNitrateNitrite), names_to = \"Nutrient\", values_to = \"Value\")\n\n\n\nCode(plot_bar_stack_rel_d7 &lt;- ggplot(data = wqdata_d7_nutrients, aes(x = Date, y = Value, fill = Nutrient)) +\n   geom_bar(stat = \"identity\", position = \"fill\")\n)",
    "crumbs": [
      "Day 3: 7/16/2024",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Making Graphs</span>"
    ]
  },
  {
    "objectID": "code/Day3_MakingGraphs.html#faceted-plots",
    "href": "code/Day3_MakingGraphs.html#faceted-plots",
    "title": "\n4  Making Graphs\n",
    "section": "\n4.10 Faceted plots",
    "text": "4.10 Faceted plots\nSometimes we want to show the same type of plot for multiple groups at once, so we can compare them. It is easy to make multi-panel plots in ggplot2 using facets.\nAbove, we plotted Secchi depth for both stations on the same plot. Sometimes, it is more useful to create a two panel plot, in which each time series is plotted on a separate graph.\n\n#faceted time series plot for Dissolved Ammonia\n(plot_ts_points_lines_facet &lt;- ggplot(data = wqdata, aes(x = Date, y = Secchi)) +\n  geom_point()+\n  geom_line())+\n  facet_grid(Station~.)\n\n\n\n\n\n\n\n\n4.10.1 Your Turn\nMake a faceted plot of nutrients for station P8 using the dataset wqdata_p8_nutrients. Show the absolute amounts rather than the relative amounts. Show the time series stacked on top of each other like the plot above for Secchi depth.\n\nCode#time series plot for two analytes\n(plot_bar_stack_abs_facet &lt;- ggplot(data = wqdata_p8_nutrients, aes(x = Date, y = Value)) +\n   geom_bar(stat = 'identity')+\n  facet_grid(Nutrient~.)\n)\n\n\nBy default, the y-axis is standardized across the panels. This is generally a good idea. However, we can change this if we like. Ammonia concentrations are much lower than nitrate + nitrite concentrations, which makes ammonia concentrations difficult to read on the plot. Let’s use different y-axis ranges for the two analytes to fix that.\n\n#time series plot for two analytes with different y-axis ranges\n(plot_bar_stack_abs_facet &lt;- ggplot(data = wqdata_p8_nutrients, aes(x = Date, y = Value)) +\n   geom_bar(stat = 'identity')+\n  facet_grid(Nutrient~., scales = \"free_y\")\n)",
    "crumbs": [
      "Day 3: 7/16/2024",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Making Graphs</span>"
    ]
  },
  {
    "objectID": "code/Day3_MakingGraphs.html#combined-plots",
    "href": "code/Day3_MakingGraphs.html#combined-plots",
    "title": "\n4  Making Graphs\n",
    "section": "\n4.11 Combined plots",
    "text": "4.11 Combined plots\nSometimes, it is useful to combine multiple plots into a panel that do not share a common x or y axis (i.e., are not produced using facet_grid() or facet_wrap()). These plot panels are particularly useful in publications like journal articles.\n\n#two side by side\nplot_hist_temp_bins + plot_bar_stack_abs\n\n\n\n\n\n\n\n\n#two stacked\nplot_hist_temp_bins / plot_bar_stack_abs\n\n\n\n\n\n\n\n\n#one large on left and two small stacked on right\nplot_hist_temp_bins+(plot_hist_temp_bins / plot_bar_stack_abs)",
    "crumbs": [
      "Day 3: 7/16/2024",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Making Graphs</span>"
    ]
  },
  {
    "objectID": "code/Day3_MakingGraphs.html#customizing-plots",
    "href": "code/Day3_MakingGraphs.html#customizing-plots",
    "title": "\n4  Making Graphs\n",
    "section": "\n4.12 Customizing plots",
    "text": "4.12 Customizing plots\nAs I mentioned at the outset, one of the greatest advantages of using R to make graphs is that you can customize them endlessly. We will touch on just a few common types of customizations.\nWe will use the Secchi depth time series again. Previously, we used color to help differentiate the two stations, but we just used the default colors. We can specify the exact colors we want. We can also change the size, shape, and color of the points and the line type, width, and color.\n\n4.12.1 Quick references for the customizations options\nColors: https://r-charts.com/colors/\nPoint shapes: \nLine types: \n\n#basic time series plot with connecting lines for both stations\n(plot_ts_points_lines_two &lt;- ggplot(data = wqdata, aes(x = Date, y = Secchi)) +\n  geom_point(aes(color = Station))+\n  geom_line(aes(color = Station)))\n\n\n\n\n\n\n#different point types for different stations\n(plot_ts_points_lines_two_pts &lt;- ggplot(data = wqdata, aes(x = Date, y = Secchi)) +\n  geom_point(aes(color = Station, shape = Station))+\n  geom_line(aes(color = Station)))\n\n\n\n\n\n\n#different line types for different stations\n(plot_ts_points_lines_two_pts &lt;- ggplot(data = wqdata, aes(x = Date, y = Secchi)) +\n  geom_point(aes(color = Station, shape = Station))+\n  geom_line(aes(color = Station, linetype = Station)))\n\n\n\n\n\n\n#adjust point sizes and line widths\n(plot_ts_points_lines_two_pts &lt;- ggplot(data = wqdata, aes(x = Date, y = Secchi)) +\n  geom_point(aes(color = Station, shape = Station), size = 3)+\n  geom_line(aes(color = Station, linetype = Station), size = 1.2))\n\n\n\n\n\n\n#Customize colors \n(plot_ts_points_lines_two_custom &lt;- ggplot(data = wqdata, aes(x = Date, y = Secchi)) +\n  geom_point(aes(color = Station, shape = Station), size = 3)+\n  geom_line(aes(color = Station, linetype = Station), size = 1.2)+\n  scale_color_manual(values =c(\"midnightblue\",\"darkorange3\"))\n)\n\n\n\n\n\n\n#Customize point shapes \n(plot_ts_points_lines_two_custom &lt;- ggplot(data = wqdata, aes(x = Date, y = Secchi)) +\n  geom_point(aes(color = Station, shape = Station), size = 3)+\n  geom_line(aes(color = Station, linetype = Station), size = 1.2)+\n  scale_color_manual(values =c(\"midnightblue\",\"darkorange3\")) +\n  scale_shape_manual(values = c(15,17))\n)\n\n\n\n\n\n\n#Customize line types\n(plot_ts_points_lines_two_custom &lt;- ggplot(data = wqdata, aes(x = Date, y = Secchi)) +\n  geom_point(aes(color = Station, shape = Station), size = 3)+\n  geom_line(aes(color = Station, linetype = Station), size = 1.2)+\n  scale_color_manual(values =c(\"midnightblue\",\"darkorange3\")) +\n  scale_shape_manual(values = c(15,17)) +\n  scale_linetype_manual(values = c(\"dotted\",\"longdash\"))\n)\n\n\n\n\n\n\n\nSo far, we have used the default color palette in ggplot2 as well as some customized colors. There are also a variety of R packages with thoughtfully developed color palettes. One example is the viridis package, which includes palettes are both attractive and color blind friendly.\n\n#Use color palette\n#our Sechi depth plot isn't a great example so we will go back to our Microcystis scores plot\n(plot_bar &lt;- ggplot(data = wqdata_means, aes(x = factor(Microcystis), y = temp_mean, fill = factor(Microcystis))) +\n   geom_bar(stat = 'identity')+\n   scale_fill_viridis(discrete = T)\n   )\n\n\n\n\n\n\n\nThere are also options for formatting the plot background. Many people dislike the default gray background with grid lines.\n\n#change background from gray with white grid to white with gray grid\n(plot_background_bw &lt;- plot_ts_points_lines_two_custom + \n  theme_bw()\n)\n\n\n\n\n\n\n(plot_background_classic &lt;- plot_ts_points_lines_two_custom + \n  theme_classic()\n)\n\n\n\n\n\n\n\nIn addition, we can customize the names used to label the x-axis and y-axis and add plot titles. It is important to provide good labels for your plot axes. In particular, make sure to include the measurement units when relevant. I don’t personally use plot title much, but they can be quickly inform your audience about the purpose of the plot.\n\n(plot_labels &lt;- plot_background_classic +\n  labs(x = \"Sampling Date\"\n       , y = \"Secchi depth (cm)\"\n       ,title = \"Secchi depth comparison\"\n       )\n)\n\n\n\n\n\n\n\n\n4.12.2 Your Turn\nUsing the Secchi depth plot, try out different point shapes, line types, and color combinations.",
    "crumbs": [
      "Day 3: 7/16/2024",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Making Graphs</span>"
    ]
  },
  {
    "objectID": "code/Day3_MakingGraphs.html#saving-plots",
    "href": "code/Day3_MakingGraphs.html#saving-plots",
    "title": "\n4  Making Graphs\n",
    "section": "\n4.13 Saving plots",
    "text": "4.13 Saving plots\nIn RStudio, you can right click on a plot to copy it and then paste it elsewhere (e.g., email, word document), which works fine as a quick and dirty approach. However, a better way to export a plot involves using the ggsave() function. We will export our customized Secchi depth comparison plot.\n\nggsave(plot = plot_labels #tell ggsave which plot to export\n       , filename = \"images/secchi_depth_comp.png\" #provide the name for the image file\n       , width = 6, height =4, units = \"in\" #dimensions of the exported image\n       , dpi = 300 #resolution of the image (dots per inch)\n       )\n\nI used PNG which is a file type that works well for viewing on a computer. However, ggsave() can save plots as PDF, JPEG, TIFF, and various others. Search for ggsave() within ‘Help’ to see the full list of file types.\nBy default, the plot will be saved in your working directory. I specified a subfolder within my working directory.",
    "crumbs": [
      "Day 3: 7/16/2024",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Making Graphs</span>"
    ]
  },
  {
    "objectID": "code/Day4_01_Outline.html",
    "href": "code/Day4_01_Outline.html",
    "title": "Day 4: 7/18/2024",
    "section": "",
    "text": "Now that we have covered the basics of using R and RStudio including importing, cleaning, and plotting data, we’ll continue with a few additional and useful beginner/intermediate skills. Here is the outline for our last day of training:\n\nSummarizing Data\n\nBasic Summarizing\nGrouping\n\nReshaping Data\n\nBasics of Data Structure\nConverting between Data Structures\n\nJoins and Binds\n\nDifferences and Usage\nBind Rows\nJoin Basics\nLeft Join\n\nOptional Extra Topics\n\nUsing across\nCombining concepts - Summarize and Reshape\n\nFinal Course Exercise\n\nMaybe have people work in pairs, Dave show solution at end (30 min)",
    "crumbs": [
      "Day 4: 7/18/2024"
    ]
  },
  {
    "objectID": "code/Day4_02_Summarizing.html",
    "href": "code/Day4_02_Summarizing.html",
    "title": "\n5  Summarizing Data\n",
    "section": "",
    "text": "5.1 Introduction\nA common task that many of us need to do is to summarize or aggregate a data set to gain a simplified overview of the data or to more easily work with the data. Some of you may be familiar with pivot tables in Excel which can help with this task. The R programming language is also very helpful with summarizing data and allows for greater customization than pivot tables. We’ll start this lesson with some basic R functions to summarize your data, and then move into some more powerful R functions from the dplyr package to group and summarize your data.",
    "crumbs": [
      "Day 4: 7/18/2024",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Summarizing Data</span>"
    ]
  },
  {
    "objectID": "code/Day4_02_Summarizing.html#import-data",
    "href": "code/Day4_02_Summarizing.html#import-data",
    "title": "\n5  Summarizing Data\n",
    "section": "\n5.2 Import Data",
    "text": "5.2 Import Data\nWe’ll start the day with loading packages and importing the EMP water quality data.\n\nlibrary(tidyverse)\nlibrary(here)\n\n\ndf_wq &lt;- read_csv(here(\"data/WQ_P8D7.csv\"))\n\nAs a reminder, here is the structure of the EMP water quality data.\n\nglimpse(df_wq)\n\nRows: 62\nColumns: 20\n$ Station            &lt;chr&gt; \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8…\n$ Date               &lt;date&gt; 2020-01-16, 2020-01-22, 2020-02-14, 2020-02-20, 20…\n$ Chla               &lt;dbl&gt; 0.64, 0.67, 1.46, 2.15, 1.40, 1.89, 4.73, 1.74, 6.4…\n$ Pheophytin         &lt;dbl&gt; 0.50, 0.87, 0.69, 0.50, 0.56, 1.13, 1.25, 0.89, 0.8…\n$ TotAlkalinity      &lt;dbl&gt; 98.0, 82.0, 81.0, 86.0, 80.0, 93.0, 59.0, 78.0, 63.…\n$ DissAmmonia        &lt;dbl&gt; 0.150, 0.210, 0.250, 0.140, 0.110, 0.220, 0.050, 0.…\n$ DissNitrateNitrite &lt;dbl&gt; 2.800, 0.490, 1.700, 0.480, 1.600, 0.380, 1.070, 0.…\n$ DOC                &lt;dbl&gt; 3.90, 0.27, 2.80, 0.39, 2.00, 0.19, 2.80, 1.20, 3.1…\n$ TOC                &lt;dbl&gt; 4.10, 0.32, 2.50, 0.41, 2.10, 0.20, 2.80, 1.20, 3.1…\n$ DON                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 0.30, 0.20, 0.30, 0.10, 0.5…\n$ TotPhos            &lt;dbl&gt; 0.310, 0.082, 0.130, 0.130, 0.190, 0.100, 0.188, 0.…\n$ DissOrthophos      &lt;dbl&gt; 0.200, 0.071, 0.130, 0.065, 0.140, 0.082, 0.177, 0.…\n$ TDS                &lt;dbl&gt; 380, 9500, 340, 5800, 290, 8700, 280, 7760, 227, 11…\n$ TSS                &lt;dbl&gt; 8.9, 38.0, 2.2, 18.0, 1.4, 28.0, 6.6, 35.6, 5.3, 23…\n$ TKN                &lt;dbl&gt; 0.520, 0.480, 0.430, 0.250, 0.400, 0.200, 0.400, 0.…\n$ Depth              &lt;dbl&gt; 28.9, 18.8, 39.0, 7.1, 39.0, 7.2, 37.1, 5.2, 36.7, …\n$ Secchi             &lt;dbl&gt; 116, 30, 212, 52, 340, 48, 100, 40, 160, 44, 120, 6…\n$ Microcystis        &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 3, 2, 3, 2, 4, 2, 3, 2, 2, 1, 1, …\n$ SpCndSurface       &lt;dbl&gt; 667, 15532, 647, 11369, 530, 16257, 503, 12946, 404…\n$ WTSurface          &lt;dbl&gt; 9.67, 9.97, 11.09, 12.51, 13.97, 13.81, 23.46, 21.1…",
    "crumbs": [
      "Day 4: 7/18/2024",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Summarizing Data</span>"
    ]
  },
  {
    "objectID": "code/Day4_02_Summarizing.html#basic-summarizing",
    "href": "code/Day4_02_Summarizing.html#basic-summarizing",
    "title": "\n5  Summarizing Data\n",
    "section": "\n5.3 Basic Summarizing",
    "text": "5.3 Basic Summarizing\nFor a basic overall summary of your data set, use the summary function. Here is what that looks like when you use it with the EMP water quality data set.\n\n# Simple overall summary statistics of entire data frame\nsummary(df_wq)\n\n   Station               Date                 Chla          Pheophytin   \n Length:62          Min.   :2020-01-16   Min.   : 0.500   Min.   :0.500  \n Class :character   1st Qu.:2020-10-19   1st Qu.: 1.530   1st Qu.:0.830  \n Mode  :character   Median :2021-09-13   Median : 2.515   Median :1.115  \n                    Mean   :2021-08-12   Mean   : 3.042   Mean   :1.350  \n                    3rd Qu.:2022-05-16   3rd Qu.: 4.188   3rd Qu.:1.472  \n                    Max.   :2022-12-19   Max.   :16.510   Max.   :6.130  \n                                                                         \n TotAlkalinity     DissAmmonia      DissNitrateNitrite      DOC       \n Min.   : 46.40   Min.   :0.05000   Min.   :0.1600     Min.   :0.190  \n 1st Qu.: 77.03   1st Qu.:0.05000   1st Qu.:0.3337     1st Qu.:1.600  \n Median : 84.60   Median :0.06850   Median :0.6830     Median :2.400  \n Mean   : 82.28   Mean   :0.09485   Mean   :1.2140     Mean   :2.751  \n 3rd Qu.: 90.95   3rd Qu.:0.11675   3rd Qu.:1.7150     3rd Qu.:3.700  \n Max.   :116.00   Max.   :0.29900   Max.   :5.4700     Max.   :9.500  \n                                                                      \n      TOC             DON            TotPhos       DissOrthophos   \n Min.   :0.200   Min.   :0.1000   Min.   :0.0820   Min.   :0.0650  \n 1st Qu.:1.500   1st Qu.:0.1900   1st Qu.:0.1190   1st Qu.:0.0930  \n Median :2.350   Median :0.2500   Median :0.1525   Median :0.1100  \n Mean   :2.734   Mean   :0.2827   Mean   :0.2052   Mean   :0.1837  \n 3rd Qu.:3.675   3rd Qu.:0.3500   3rd Qu.:0.2893   3rd Qu.:0.2838  \n Max.   :9.100   Max.   :1.0700   Max.   :0.4900   Max.   :0.4740  \n                 NA's   :6                                         \n      TDS               TSS               TKN             Depth      \n Min.   :  152.0   Min.   :  1.400   Min.   :0.1490   Min.   : 5.20  \n 1st Qu.:  307.5   1st Qu.:  4.575   1st Qu.:0.3020   1st Qu.: 6.20  \n Median : 2169.0   Median : 13.100   Median :0.3950   Median :12.80  \n Mean   : 5819.7   Mean   : 26.906   Mean   :0.4295   Mean   :21.18  \n 3rd Qu.:12125.0   3rd Qu.: 39.500   3rd Qu.:0.5222   3rd Qu.:37.33  \n Max.   :15800.0   Max.   :105.000   Max.   :1.4400   Max.   :42.00  \n                                                                     \n     Secchi        Microcystis     SpCndSurface       WTSurface    \n Min.   : 20.00   Min.   :1.000   Min.   :  278.0   Min.   : 9.06  \n 1st Qu.: 40.00   1st Qu.:1.000   1st Qu.:  548.8   1st Qu.:13.51  \n Median : 68.00   Median :1.000   Median : 3714.0   Median :19.05  \n Mean   : 93.49   Mean   :1.548   Mean   : 9771.1   Mean   :18.18  \n 3rd Qu.:144.00   3rd Qu.:2.000   3rd Qu.:20329.0   3rd Qu.:22.11  \n Max.   :340.00   Max.   :4.000   Max.   :25278.0   Max.   :27.01  \n NA's   :1                                                         \n\n\nYou can see that R provided a set of simple summary statistics (min, 25th and 75th quartiles, median, mean, max) for each column in the data frame. If you are interested in summary statistics for a single column in the data frame, you can use the data$column notation to subset your data set. If we wanted summary statistics of just chlorophyll-a, you could use:\n\n# Summary of one column\nsummary(df_wq$Chla)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.500   1.530   2.515   3.042   4.188  16.510 \n\n\nR provided the same set of simple summary statistics for just the Chla column.\nNow, we’ll introduce a more powerful summarizing function from the dplyr package called summarize. We’ll start by using it to calculate some simple summary statistics. First, we’ll calculate the overall average of all chlorophyll-a data in the data set.\n\n# Calculate overall mean of one column\ndf_wq %&gt;% summarize(mean_Chla = mean(Chla))\n\n# A tibble: 1 × 1\n  mean_Chla\n      &lt;dbl&gt;\n1      3.04\n\n\nYou may have noticed that unlike the summary function, summarize provides the summarized data in a tibble or data frame. This is useful if you intend to continue working with the data. Also note that I provided a name for the summarized data column “mean_Chla”, which is a lot like the dplyr::mutate function we learned about earlier.\nYou can calculate multiple values at once by providing additional arguments to summarize. For example, let’s calculate the overall averages of both chlorophyll-a and Pheophytin.\n\n# Calculate overall mean of multiple columns\ndf_wq %&gt;% summarize(mean_Chla = mean(Chla), mean_Pheo = mean(Pheophytin))\n\n# A tibble: 1 × 2\n  mean_Chla mean_Pheo\n      &lt;dbl&gt;     &lt;dbl&gt;\n1      3.04      1.35\n\n\nR provides a 2-column tibble with our desired summary statistics. When using summarize, be mindful of NA values in your data columns. For example, DON has a few NA values - here is what happens when we try to calculate its mean:\n\ndf_wq %&gt;% summarize(mean_DON = mean(DON))\n\n# A tibble: 1 × 1\n  mean_DON\n     &lt;dbl&gt;\n1       NA\n\n\nNotice that it returns NA. If you want summarize to ignore or drop the NA values when making calculations, you’ll need to add the na.rm = TRUE argument to your summary function which in this case is mean.\n\ndf_wq %&gt;% summarize(mean_DON = mean(DON, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  mean_DON\n     &lt;dbl&gt;\n1    0.283\n\n\nNow, R returns the overall average DON value after ignoring the NA values.\n\n5.3.1 Exercise\nNow its your turn to try out these summarizing functions we just learned about.\n\nUse summary to provide simple summary statistics for “Secchi” and “WTSurface”.HINT: Run the function on one column at a time.\nNow, use summarize to calculate the overall minimum value for “Secchi”.HINT: Watch out for NA values!\nAdd the minimum value for “WTSurface” to the summarize function used above, and assign it to an object called “df_wq_min”, and print it to view the results.\n\nClick below for the answer when you are done!\n\nCode# Use summary to calculate simple summary statistics for Secchi\nsummary(df_wq$Secchi)\n\n# Use summary to calculate simple summary statistics for WTSurface\nsummary(df_wq$WTSurface)\n\n# Use summarize to calculate the overall minimum value for Secchi\ndf_wq %&gt;% summarize(min_Secchi = min(Secchi, na.rm = TRUE))\n\n# Add the minimum value for \"WTSurface\" and assign it to an object called \"df_wq_min\"\ndf_wq_min &lt;- df_wq %&gt;% \n  summarize(\n    min_Secchi = min(Secchi, na.rm = TRUE),\n    min_WTSurface = min(WTSurface)\n  )\n\n# Print df_wq_min to see results\ndf_wq_min",
    "crumbs": [
      "Day 4: 7/18/2024",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Summarizing Data</span>"
    ]
  },
  {
    "objectID": "code/Day4_02_Summarizing.html#grouping",
    "href": "code/Day4_02_Summarizing.html#grouping",
    "title": "\n5  Summarizing Data\n",
    "section": "\n5.4 Grouping",
    "text": "5.4 Grouping\nCalculating overall summary statistics is useful, but the real power of summarize becomes more apparent when its used in combination with the group_by function (also within the dplyr package). Using group_by with summarize allows for calculating summary statistics for groups of data within your data set. Examples include averages for each station, seasonal and annual statistics, or other combinations that you can imagine. Here is a simple example using these two functions to calculate overall average chlorophyll-a values for each station in the EMP water quality data set (D7 and P8).\n\n# Group by Station\ndf_wq %&gt;% group_by(Station) %&gt;% summarize(mean_Chla = mean(Chla))\n\n# A tibble: 2 × 2\n  Station mean_Chla\n  &lt;chr&gt;       &lt;dbl&gt;\n1 D7           2.71\n2 P8           3.37\n\n\nYou’ll see that now we have an additional column added to the tibble for “Station”, and the “mean_Chla” column contains the average values for each station. As with the example in the Basic Summarizing section above, you can calculate multiple values at once for each group by providing additional arguments to summarize.\n\n# Calculate more than one summary statistic within `summarize`\ndf_wq %&gt;% \n  group_by(Station) %&gt;% \n  summarize(\n    min_Chla = min(Chla),\n    mean_Chla = mean(Chla),\n    median_Chla = median(Chla),\n    max_Chla = max(Chla),\n    sd_Chla = sd(Chla)\n  )\n\n# A tibble: 2 × 6\n  Station min_Chla mean_Chla median_Chla max_Chla sd_Chla\n  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 D7          0.5       2.71        2.21     7.36    1.81\n2 P8          0.57      3.37        2.67    16.5     2.92\n\n\nYou can also group by more than one variable at a time. For example, the EMP water quality data set contains data from multiple years (2020-2022). We can calculate the same series of summary statistics for chlorophyll-a in the prior example for each station and year combination.\n\n# First, we add a second grouping variable for year, creating a new object for\n  # the resulting data frame\ndf_wq_c &lt;- df_wq %&gt;% mutate(Year = year(Date))\n\n# Next, we calculate summary statistics for Chla for each station and year\n  # combination\ndf_wq_c %&gt;% \n  group_by(Station, Year) %&gt;% \n  summarize(\n    min_Chla = min(Chla),\n    mean_Chla = mean(Chla),\n    median_Chla = median(Chla),\n    max_Chla = max(Chla),\n    sd_Chla = sd(Chla)\n  )\n\n# A tibble: 6 × 7\n# Groups:   Station [2]\n  Station  Year min_Chla mean_Chla median_Chla max_Chla sd_Chla\n  &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 D7       2020     0.5       1.53        1.74     2.79   0.749\n2 D7       2021     1.17      3.58        3.12     6.76   1.97 \n3 D7       2022     0.67      2.88        2.51     7.36   1.87 \n4 P8       2020     0.64      4.48        2.81    16.5    4.88 \n5 P8       2021     1.25      3.18        3.24     5.56   1.57 \n6 P8       2022     0.57      2.70        2.58     5.24   1.54 \n\n\nWow, now we are starting to get somewhere with summarizing our data set. You’ll see that now we have an another column added to the tibble for “Year in addition to”Station” with the desired summary statistics for each combination in the following columns. You may also have noticed that the printout of the tibble indicates that it is still grouped by “Station”. This is because the default behavior of using summarize after group_by is to drop the last level of grouping (“Year”) in its output. It is always good practice to ungroup a data frame when you no longer need it to be grouped because you can get unintended results when using other functions on it. You can ungroup the data frame by using the ungroup function within the dplyr package.\n\n# Always best practice to ungroup data after finished with operation\ndf_wq_c %&gt;% \n  group_by(Station, Year) %&gt;% \n  summarize(\n    min_Chla = min(Chla),\n    mean_Chla = mean(Chla),\n    median_Chla = median(Chla),\n    max_Chla = max(Chla),\n    sd_Chla = sd(Chla)\n  ) %&gt;% \n  ungroup()\n\n# A tibble: 6 × 7\n  Station  Year min_Chla mean_Chla median_Chla max_Chla sd_Chla\n  &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 D7       2020     0.5       1.53        1.74     2.79   0.749\n2 D7       2021     1.17      3.58        3.12     6.76   1.97 \n3 D7       2022     0.67      2.88        2.51     7.36   1.87 \n4 P8       2020     0.64      4.48        2.81    16.5    4.88 \n5 P8       2021     1.25      3.18        3.24     5.56   1.57 \n6 P8       2022     0.57      2.70        2.58     5.24   1.54 \n\n\nNow, you see that the output data frame is no longer grouped. A useful trick is to use the .by argument within summarize to temporarily group the data frame just for the summarize operation.\n\n# It's possible to group data within `summarize`\ndf_wq_c %&gt;% \n  summarize(\n    min_Chla = min(Chla),\n    mean_Chla = mean(Chla),\n    median_Chla = median(Chla),\n    max_Chla = max(Chla),\n    sd_Chla = sd(Chla),\n    .by = c(Station, Year)\n  ) \n\n# A tibble: 6 × 7\n  Station  Year min_Chla mean_Chla median_Chla max_Chla sd_Chla\n  &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 P8       2020     0.64      4.48        2.81    16.5    4.88 \n2 D7       2020     0.5       1.53        1.74     2.79   0.749\n3 P8       2021     1.25      3.18        3.24     5.56   1.57 \n4 D7       2021     1.17      3.58        3.12     6.76   1.97 \n5 D7       2022     0.67      2.88        2.51     7.36   1.87 \n6 P8       2022     0.57      2.70        2.58     5.24   1.54 \n\n\nWe won’t cover it here, but the group_by function also works with other functions in the dplyr package including mutate, filter, and arrange. There are also many other useful things you can do with the summarize function that we may not have enough time to discuss including using it with the across function. Please see the Optional Extra Topics chapter for more information.\n\n\n\n\n\n\nSummarize vs. Mutate\n\n\n\nYou may be wondering how summarize and mutate are different since they both do similar things. The main difference is that mutate always returns the same number of rows in the data frame, and summarize returns just one row for the specified summary function(s). summarize with group_by returns a row for each combination of grouping variables.\n\n\n\n5.4.1 Exercise\nNow its your turn to try out grouping and summarizing.\n\nUse group_by and summarize to calculate the minimum, median, and maximum values for “Secchi” for each station.HINT: Watch out for NA values!\nAdd “Year” as a grouping variable to the operation above to calculate summary statistics for “Secchi” for each station and year combination.HINT: Don’t forget to ungroup your output data frame!\nTry the same as in #2 above, but use the .by argument within the summarize function.\n\nClick below for the answer when you are done!\n\nCode# Calculate the minimum, median, and maximum values for Secchi for each station\ndf_wq %&gt;% \n  group_by(Station) %&gt;% \n  summarize(\n    min_Secchi = min(Secchi, na.rm = TRUE),\n    median_Secchi = median(Secchi, na.rm = TRUE),\n    max_Secchi = max(Secchi, na.rm = TRUE)\n  )\n\n# Add \"Year\" as a grouping variable to the operation above\ndf_wq %&gt;% \n  mutate(Year = year(Date)) %&gt;% \n  group_by(Station, Year) %&gt;% \n  summarize(\n    min_Secchi = min(Secchi, na.rm = TRUE),\n    median_Secchi = median(Secchi, na.rm = TRUE),\n    max_Secchi = max(Secchi, na.rm = TRUE)\n  ) %&gt;% \n  ungroup()\n\n# Try the same as in the operation above, but use the `.by` argument within the `summarize` function.\ndf_wq %&gt;% \n  mutate(Year = year(Date)) %&gt;% \n  summarize(\n    min_Secchi = min(Secchi, na.rm = TRUE),\n    median_Secchi = median(Secchi, na.rm = TRUE),\n    max_Secchi = max(Secchi, na.rm = TRUE),\n    .by = c(Station, Year)\n  )",
    "crumbs": [
      "Day 4: 7/18/2024",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Summarizing Data</span>"
    ]
  },
  {
    "objectID": "code/Day4_03_Reshaping.html",
    "href": "code/Day4_03_Reshaping.html",
    "title": "\n6  Reshaping Data\n",
    "section": "",
    "text": "6.1 Basics of Data Structure\nImage Credit: https://www.statology.org/long-vs-wide-data/",
    "crumbs": [
      "Day 4: 7/18/2024",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Reshaping Data</span>"
    ]
  },
  {
    "objectID": "code/Day4_03_Reshaping.html#converting-between-data-structures",
    "href": "code/Day4_03_Reshaping.html#converting-between-data-structures",
    "title": "\n6  Reshaping Data\n",
    "section": "\n6.2 Converting between Data Structures",
    "text": "6.2 Converting between Data Structures\n\ndf_wq_nutr &lt;- df_wq %&gt;% \n  select(Station, Date, DissAmmonia, DissNitrateNitrite, DissOrthophos)\n\ndf_wq_nutr\n\n# A tibble: 62 × 5\n   Station Date       DissAmmonia DissNitrateNitrite DissOrthophos\n   &lt;chr&gt;   &lt;date&gt;           &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n 1 P8      2020-01-16        0.15               2.8          0.2  \n 2 D7      2020-01-22        0.21               0.49         0.071\n 3 P8      2020-02-14        0.25               1.7          0.13 \n 4 D7      2020-02-20        0.14               0.48         0.065\n 5 P8      2020-03-03        0.11               1.6          0.14 \n 6 D7      2020-03-06        0.22               0.38         0.082\n 7 P8      2020-06-11        0.05               1.07         0.177\n 8 D7      2020-06-17        0.05               0.4          0.095\n 9 P8      2020-07-13        0.05               0.71         0.171\n10 D7      2020-07-16        0.05               0.32         0.093\n# ℹ 52 more rows\n\n\n\n6.2.1 “Wide” to “Long”\n\ndf_wq_nutr_long &lt;- df_wq_nutr %&gt;% \n  pivot_longer(\n    cols = c(DissAmmonia, DissNitrateNitrite, DissOrthophos),\n    names_to = \"Parameter\",\n    values_to = \"Value\"\n  )\n\nprint(df_wq_nutr_long, n = 30)\n\n# A tibble: 186 × 4\n   Station Date       Parameter          Value\n   &lt;chr&gt;   &lt;date&gt;     &lt;chr&gt;              &lt;dbl&gt;\n 1 P8      2020-01-16 DissAmmonia        0.15 \n 2 P8      2020-01-16 DissNitrateNitrite 2.8  \n 3 P8      2020-01-16 DissOrthophos      0.2  \n 4 D7      2020-01-22 DissAmmonia        0.21 \n 5 D7      2020-01-22 DissNitrateNitrite 0.49 \n 6 D7      2020-01-22 DissOrthophos      0.071\n 7 P8      2020-02-14 DissAmmonia        0.25 \n 8 P8      2020-02-14 DissNitrateNitrite 1.7  \n 9 P8      2020-02-14 DissOrthophos      0.13 \n10 D7      2020-02-20 DissAmmonia        0.14 \n11 D7      2020-02-20 DissNitrateNitrite 0.48 \n12 D7      2020-02-20 DissOrthophos      0.065\n13 P8      2020-03-03 DissAmmonia        0.11 \n14 P8      2020-03-03 DissNitrateNitrite 1.6  \n15 P8      2020-03-03 DissOrthophos      0.14 \n16 D7      2020-03-06 DissAmmonia        0.22 \n17 D7      2020-03-06 DissNitrateNitrite 0.38 \n18 D7      2020-03-06 DissOrthophos      0.082\n19 P8      2020-06-11 DissAmmonia        0.05 \n20 P8      2020-06-11 DissNitrateNitrite 1.07 \n21 P8      2020-06-11 DissOrthophos      0.177\n22 D7      2020-06-17 DissAmmonia        0.05 \n23 D7      2020-06-17 DissNitrateNitrite 0.4  \n24 D7      2020-06-17 DissOrthophos      0.095\n25 P8      2020-07-13 DissAmmonia        0.05 \n26 P8      2020-07-13 DissNitrateNitrite 0.71 \n27 P8      2020-07-13 DissOrthophos      0.171\n28 D7      2020-07-16 DissAmmonia        0.05 \n29 D7      2020-07-16 DissNitrateNitrite 0.32 \n30 D7      2020-07-16 DissOrthophos      0.093\n# ℹ 156 more rows\n\n\n\n6.2.2 “Long” to “Wide”\n\ndf_wq_nutr_wide &lt;- df_wq_nutr_long %&gt;% \n  pivot_wider(names_from = Parameter, values_from = Value)\n\ndf_wq_nutr_wide\n\n# A tibble: 62 × 5\n   Station Date       DissAmmonia DissNitrateNitrite DissOrthophos\n   &lt;chr&gt;   &lt;date&gt;           &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n 1 P8      2020-01-16        0.15               2.8          0.2  \n 2 D7      2020-01-22        0.21               0.49         0.071\n 3 P8      2020-02-14        0.25               1.7          0.13 \n 4 D7      2020-02-20        0.14               0.48         0.065\n 5 P8      2020-03-03        0.11               1.6          0.14 \n 6 D7      2020-03-06        0.22               0.38         0.082\n 7 P8      2020-06-11        0.05               1.07         0.177\n 8 D7      2020-06-17        0.05               0.4          0.095\n 9 P8      2020-07-13        0.05               0.71         0.171\n10 D7      2020-07-16        0.05               0.32         0.093\n# ℹ 52 more rows\n\n\n\n6.2.3 Exercise",
    "crumbs": [
      "Day 4: 7/18/2024",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Reshaping Data</span>"
    ]
  },
  {
    "objectID": "code/Day4_04_Joins_Binds.html",
    "href": "code/Day4_04_Joins_Binds.html",
    "title": "\n7  Joins and Binds\n",
    "section": "",
    "text": "7.1 Differences between them\nBinding rows or columns from two dataframes:\nRarely use bind_cols, safer to use a join function\nJoining two dataframes with a left_join():\nImage Credit: https://stat545.stat.ubc.ca/tutorials/tibble_join/",
    "crumbs": [
      "Day 4: 7/18/2024",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Joins and Binds</span>"
    ]
  },
  {
    "objectID": "code/Day4_04_Joins_Binds.html#bind-rows",
    "href": "code/Day4_04_Joins_Binds.html#bind-rows",
    "title": "\n7  Joins and Binds\n",
    "section": "\n7.2 Bind rows",
    "text": "7.2 Bind rows\nImport additional WQ data collected in 2019 at P8 and D7\n\ndf_wq_2019 &lt;- read_csv(here(\"data/WQ_2019.csv\"))\n\nLook at structure of both dataframes to bind\n\n# 2020-2022 data:\nglimpse(df_wq)\n\nRows: 62\nColumns: 20\n$ Station            &lt;chr&gt; \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8…\n$ Date               &lt;date&gt; 2020-01-16, 2020-01-22, 2020-02-14, 2020-02-20, 20…\n$ Chla               &lt;dbl&gt; 0.64, 0.67, 1.46, 2.15, 1.40, 1.89, 4.73, 1.74, 6.4…\n$ Pheophytin         &lt;dbl&gt; 0.50, 0.87, 0.69, 0.50, 0.56, 1.13, 1.25, 0.89, 0.8…\n$ TotAlkalinity      &lt;dbl&gt; 98.0, 82.0, 81.0, 86.0, 80.0, 93.0, 59.0, 78.0, 63.…\n$ DissAmmonia        &lt;dbl&gt; 0.150, 0.210, 0.250, 0.140, 0.110, 0.220, 0.050, 0.…\n$ DissNitrateNitrite &lt;dbl&gt; 2.800, 0.490, 1.700, 0.480, 1.600, 0.380, 1.070, 0.…\n$ DOC                &lt;dbl&gt; 3.90, 0.27, 2.80, 0.39, 2.00, 0.19, 2.80, 1.20, 3.1…\n$ TOC                &lt;dbl&gt; 4.10, 0.32, 2.50, 0.41, 2.10, 0.20, 2.80, 1.20, 3.1…\n$ DON                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 0.30, 0.20, 0.30, 0.10, 0.5…\n$ TotPhos            &lt;dbl&gt; 0.310, 0.082, 0.130, 0.130, 0.190, 0.100, 0.188, 0.…\n$ DissOrthophos      &lt;dbl&gt; 0.200, 0.071, 0.130, 0.065, 0.140, 0.082, 0.177, 0.…\n$ TDS                &lt;dbl&gt; 380, 9500, 340, 5800, 290, 8700, 280, 7760, 227, 11…\n$ TSS                &lt;dbl&gt; 8.9, 38.0, 2.2, 18.0, 1.4, 28.0, 6.6, 35.6, 5.3, 23…\n$ TKN                &lt;dbl&gt; 0.520, 0.480, 0.430, 0.250, 0.400, 0.200, 0.400, 0.…\n$ Depth              &lt;dbl&gt; 28.9, 18.8, 39.0, 7.1, 39.0, 7.2, 37.1, 5.2, 36.7, …\n$ Secchi             &lt;dbl&gt; 116, 30, 212, 52, 340, 48, 100, 40, 160, 44, 120, 6…\n$ Microcystis        &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 3, 2, 3, 2, 4, 2, 3, 2, 2, 1, 1, …\n$ SpCndSurface       &lt;dbl&gt; 667, 15532, 647, 11369, 530, 16257, 503, 12946, 404…\n$ WTSurface          &lt;dbl&gt; 9.67, 9.97, 11.09, 12.51, 13.97, 13.81, 23.46, 21.1…\n\nnames(df_wq)\n\n [1] \"Station\"            \"Date\"               \"Chla\"              \n [4] \"Pheophytin\"         \"TotAlkalinity\"      \"DissAmmonia\"       \n [7] \"DissNitrateNitrite\" \"DOC\"                \"TOC\"               \n[10] \"DON\"                \"TotPhos\"            \"DissOrthophos\"     \n[13] \"TDS\"                \"TSS\"                \"TKN\"               \n[16] \"Depth\"              \"Secchi\"             \"Microcystis\"       \n[19] \"SpCndSurface\"       \"WTSurface\"         \n\n# 2019 data:\nglimpse(df_wq_2019)\n\nRows: 24\nColumns: 20\n$ Station            &lt;chr&gt; \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8…\n$ Date               &lt;date&gt; 2019-01-15, 2019-01-17, 2019-02-15, 2019-02-20, 20…\n$ Chla               &lt;dbl&gt; 0.84, 0.88, 2.29, 1.92, 2.60, 2.53, 1.59, 2.81, 1.0…\n$ Pheophytin         &lt;dbl&gt; 1.21, 0.64, 1.03, 2.32, 1.42, 1.35, 1.25, 1.19, 0.5…\n$ TotAlkalinity      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ DissAmmonia        &lt;dbl&gt; 0.200, 0.214, 0.090, 0.070, 0.050, 0.050, 0.050, 0.…\n$ DissNitrateNitrite &lt;dbl&gt; 3.600, 0.570, 1.030, 0.370, 0.540, 0.300, 0.420, 0.…\n$ DOC                &lt;dbl&gt; 6.00, 1.70, 6.10, 4.20, 3.60, 2.50, 2.60, 2.30, 2.2…\n$ TOC                &lt;dbl&gt; 6.00, 1.70, 5.60, 4.20, 3.60, 2.50, 2.60, 2.10, 2.2…\n$ DON                &lt;dbl&gt; 0.50, 0.10, 0.50, 0.30, 0.38, 0.20, 0.20, 0.16, 0.2…\n$ TotPhos            &lt;dbl&gt; 0.370, 0.094, 0.153, 0.180, 0.070, 0.080, 0.100, 0.…\n$ DissOrthophos      &lt;dbl&gt; 0.329, 0.092, 0.120, 0.071, 0.075, 0.065, 0.072, 0.…\n$ TDS                &lt;dbl&gt; 491, 8530, 160, 133, 112, 108, 109, 94, 118, 150, 5…\n$ TSS                &lt;dbl&gt; 12.0, 24.0, 17.0, 108.0, 6.0, 36.0, 27.0, 22.0, 4.0…\n$ TKN                &lt;dbl&gt; 0.800, 0.380, 0.700, 0.600, 0.400, 0.400, 0.300, 0.…\n$ Depth              &lt;dbl&gt; 38.7, 8.2, 17.0, 8.0, 36.7, 8.2, 39.0, 7.0, 37.8, 6…\n$ Secchi             &lt;dbl&gt; 100, 52, 44, 16, 76, 28, 92, 28, 100, 40, 80, 44, 1…\n$ Microcystis        &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 4, …\n$ SpCndSurface       &lt;dbl&gt; 878, 14498, 276, 228, 194, 189, 195, 168, 214, 276,…\n$ WTSurface          &lt;dbl&gt; 10.03, 10.37, 10.87, 9.19, 12.12, 12.70, 14.26, 14.…\n\nnames(df_wq_2019)\n\n [1] \"Station\"            \"Date\"               \"Chla\"              \n [4] \"Pheophytin\"         \"TotAlkalinity\"      \"DissAmmonia\"       \n [7] \"DissNitrateNitrite\" \"DOC\"                \"TOC\"               \n[10] \"DON\"                \"TotPhos\"            \"DissOrthophos\"     \n[13] \"TDS\"                \"TSS\"                \"TKN\"               \n[16] \"Depth\"              \"Secchi\"             \"Microcystis\"       \n[19] \"SpCndSurface\"       \"WTSurface\"         \n\n\nAdd 2019 data to 2020-2022 data by binding rows:\n\ndf_wq_2019_2022 &lt;- bind_rows(df_wq_2019, df_wq)\ndf_wq_2019_2022\n\n# A tibble: 86 × 20\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2019-01-15  0.84       1.21            NA       0.2  \n 2 D7      2019-01-17  0.88       0.64            NA       0.214\n 3 P8      2019-02-15  2.29       1.03            NA       0.09 \n 4 D7      2019-02-20  1.92       2.32            NA       0.07 \n 5 P8      2019-03-14  2.6        1.42            NA       0.05 \n 6 D7      2019-03-18  2.53       1.35            NA       0.05 \n 7 P8      2019-04-12  1.59       1.25            NA       0.05 \n 8 D7      2019-04-16  2.81       1.19            NA       0.05 \n 9 P8      2019-05-13  1.03       0.5             NA       0.05 \n10 D7      2019-05-15  2.1        0.69            NA       0.05 \n# ℹ 76 more rows\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\n7.2.1 Exercise\nAdd data collected from 2019-2022 at C3A to dataframe with P8 and D7",
    "crumbs": [
      "Day 4: 7/18/2024",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Joins and Binds</span>"
    ]
  },
  {
    "objectID": "code/Day4_04_Joins_Binds.html#join-basics",
    "href": "code/Day4_04_Joins_Binds.html#join-basics",
    "title": "\n7  Joins and Binds\n",
    "section": "\n7.3 Join basics",
    "text": "7.3 Join basics",
    "crumbs": [
      "Day 4: 7/18/2024",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Joins and Binds</span>"
    ]
  },
  {
    "objectID": "code/Day4_04_Joins_Binds.html#left-join",
    "href": "code/Day4_04_Joins_Binds.html#left-join",
    "title": "\n7  Joins and Binds\n",
    "section": "\n7.4 Left join",
    "text": "7.4 Left join\nJoin Delta inflow and outflow data from DayFlow to WQ data\n\n# Import Delta inflow and outflow data\ndf_dayflow &lt;- read_csv(here(\"data/Dayflow_2019_2023.csv\"))\n\n# Join Delta flow data to 2019-2022 WQ data\ndf_wq_flow &lt;- left_join(df_wq_2019_2022, df_dayflow)\nglimpse(df_wq_flow)\n\nRows: 86\nColumns: 22\n$ Station            &lt;chr&gt; \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8…\n$ Date               &lt;date&gt; 2019-01-15, 2019-01-17, 2019-02-15, 2019-02-20, 20…\n$ Chla               &lt;dbl&gt; 0.84, 0.88, 2.29, 1.92, 2.60, 2.53, 1.59, 2.81, 1.0…\n$ Pheophytin         &lt;dbl&gt; 1.21, 0.64, 1.03, 2.32, 1.42, 1.35, 1.25, 1.19, 0.5…\n$ TotAlkalinity      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ DissAmmonia        &lt;dbl&gt; 0.200, 0.214, 0.090, 0.070, 0.050, 0.050, 0.050, 0.…\n$ DissNitrateNitrite &lt;dbl&gt; 3.600, 0.570, 1.030, 0.370, 0.540, 0.300, 0.420, 0.…\n$ DOC                &lt;dbl&gt; 6.00, 1.70, 6.10, 4.20, 3.60, 2.50, 2.60, 2.30, 2.2…\n$ TOC                &lt;dbl&gt; 6.00, 1.70, 5.60, 4.20, 3.60, 2.50, 2.60, 2.10, 2.2…\n$ DON                &lt;dbl&gt; 0.50, 0.10, 0.50, 0.30, 0.38, 0.20, 0.20, 0.16, 0.2…\n$ TotPhos            &lt;dbl&gt; 0.370, 0.094, 0.153, 0.180, 0.070, 0.080, 0.100, 0.…\n$ DissOrthophos      &lt;dbl&gt; 0.329, 0.092, 0.120, 0.071, 0.075, 0.065, 0.072, 0.…\n$ TDS                &lt;dbl&gt; 491, 8530, 160, 133, 112, 108, 109, 94, 118, 150, 5…\n$ TSS                &lt;dbl&gt; 12.0, 24.0, 17.0, 108.0, 6.0, 36.0, 27.0, 22.0, 4.0…\n$ TKN                &lt;dbl&gt; 0.800, 0.380, 0.700, 0.600, 0.400, 0.400, 0.300, 0.…\n$ Depth              &lt;dbl&gt; 38.7, 8.2, 17.0, 8.0, 36.7, 8.2, 39.0, 7.0, 37.8, 6…\n$ Secchi             &lt;dbl&gt; 100, 52, 44, 16, 76, 28, 92, 28, 100, 40, 80, 44, 1…\n$ Microcystis        &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 4, …\n$ SpCndSurface       &lt;dbl&gt; 878, 14498, 276, 228, 194, 189, 195, 168, 214, 276,…\n$ WTSurface          &lt;dbl&gt; 10.03, 10.37, 10.87, 9.19, 12.12, 12.70, 14.26, 14.…\n$ Inflow             &lt;dbl&gt; 27349, 42029, 129533, 107109, 129444, 105932, 10488…\n$ Outflow            &lt;dbl&gt; 21963, 42727, 130451, 95024, 121805, 97089, 100003,…\n\n\n\n7.4.1 Exercise\nAdd weather observation data to WQ data (2019-2022, P8, D7, and C3A)",
    "crumbs": [
      "Day 4: 7/18/2024",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Joins and Binds</span>"
    ]
  },
  {
    "objectID": "code/Day4_05_Extras.html",
    "href": "code/Day4_05_Extras.html",
    "title": "\n8  Optional Extra Topics\n",
    "section": "",
    "text": "8.1 Using across\nglimpse(df_wq_c)\n\nRows: 62\nColumns: 21\n$ Station            &lt;chr&gt; \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8…\n$ Date               &lt;date&gt; 2020-01-16, 2020-01-22, 2020-02-14, 2020-02-20, 20…\n$ Chla               &lt;dbl&gt; 0.64, 0.67, 1.46, 2.15, 1.40, 1.89, 4.73, 1.74, 6.4…\n$ Pheophytin         &lt;dbl&gt; 0.50, 0.87, 0.69, 0.50, 0.56, 1.13, 1.25, 0.89, 0.8…\n$ TotAlkalinity      &lt;dbl&gt; 98.0, 82.0, 81.0, 86.0, 80.0, 93.0, 59.0, 78.0, 63.…\n$ DissAmmonia        &lt;dbl&gt; 0.150, 0.210, 0.250, 0.140, 0.110, 0.220, 0.050, 0.…\n$ DissNitrateNitrite &lt;dbl&gt; 2.800, 0.490, 1.700, 0.480, 1.600, 0.380, 1.070, 0.…\n$ DOC                &lt;dbl&gt; 3.90, 0.27, 2.80, 0.39, 2.00, 0.19, 2.80, 1.20, 3.1…\n$ TOC                &lt;dbl&gt; 4.10, 0.32, 2.50, 0.41, 2.10, 0.20, 2.80, 1.20, 3.1…\n$ DON                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 0.30, 0.20, 0.30, 0.10, 0.5…\n$ TotPhos            &lt;dbl&gt; 0.310, 0.082, 0.130, 0.130, 0.190, 0.100, 0.188, 0.…\n$ DissOrthophos      &lt;dbl&gt; 0.200, 0.071, 0.130, 0.065, 0.140, 0.082, 0.177, 0.…\n$ TDS                &lt;dbl&gt; 380, 9500, 340, 5800, 290, 8700, 280, 7760, 227, 11…\n$ TSS                &lt;dbl&gt; 8.9, 38.0, 2.2, 18.0, 1.4, 28.0, 6.6, 35.6, 5.3, 23…\n$ TKN                &lt;dbl&gt; 0.520, 0.480, 0.430, 0.250, 0.400, 0.200, 0.400, 0.…\n$ Depth              &lt;dbl&gt; 28.9, 18.8, 39.0, 7.1, 39.0, 7.2, 37.1, 5.2, 36.7, …\n$ Secchi             &lt;dbl&gt; 116, 30, 212, 52, 340, 48, 100, 40, 160, 44, 120, 6…\n$ Microcystis        &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 3, 2, 3, 2, 4, 2, 3, 2, 2, 1, 1, …\n$ SpCndSurface       &lt;dbl&gt; 667, 15532, 647, 11369, 530, 16257, 503, 12946, 404…\n$ WTSurface          &lt;dbl&gt; 9.67, 9.97, 11.09, 12.51, 13.97, 13.81, 23.46, 21.1…\n$ Year               &lt;dbl&gt; 2020, 2020, 2020, 2020, 2020, 2020, 2020, 2020, 202…\ndf_wq_c %&gt;% \n  group_by(Station, Year) %&gt;% \n  summarize(across(c(DissAmmonia, DissNitrateNitrite, DissOrthophos), max)) %&gt;% \n  ungroup()\n\n# A tibble: 6 × 5\n  Station  Year DissAmmonia DissNitrateNitrite DissOrthophos\n  &lt;chr&gt;   &lt;dbl&gt;       &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n1 D7       2020       0.22               0.49          0.103\n2 D7       2021       0.192              0.526         0.103\n3 D7       2022       0.145              0.656         0.113\n4 P8       2020       0.25               3.25          0.474\n5 P8       2021       0.299              3.58          0.455\n6 P8       2022       0.29               5.47          0.456\ndf_wq_c %&gt;% \n  group_by(Station, Year) %&gt;% \n  summarize(\n    across(\n      c(DissAmmonia, DissNitrateNitrite, DissOrthophos), \n      list(min = min, max = max)\n    )\n  ) %&gt;% \n  ungroup()\n\n# A tibble: 6 × 8\n  Station  Year DissAmmonia_min DissAmmonia_max DissNitrateNitrite_min\n  &lt;chr&gt;   &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;                  &lt;dbl&gt;\n1 D7       2020            0.05           0.22                   0.23 \n2 D7       2021            0.05           0.192                  0.179\n3 D7       2022            0.05           0.145                  0.16 \n4 P8       2020            0.05           0.25                   0.71 \n5 P8       2021            0.05           0.299                  1.08 \n6 P8       2022            0.05           0.29                   0.8  \n# ℹ 3 more variables: DissNitrateNitrite_max &lt;dbl&gt;, DissOrthophos_min &lt;dbl&gt;,\n#   DissOrthophos_max &lt;dbl&gt;\ndf_wq_c %&gt;% \n  group_by(Station, Year) %&gt;% \n  summarize(across(starts_with(\"Diss\"), list(min = min, max = max))) %&gt;% \n  ungroup()\n\n# A tibble: 6 × 8\n  Station  Year DissAmmonia_min DissAmmonia_max DissNitrateNitrite_min\n  &lt;chr&gt;   &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;                  &lt;dbl&gt;\n1 D7       2020            0.05           0.22                   0.23 \n2 D7       2021            0.05           0.192                  0.179\n3 D7       2022            0.05           0.145                  0.16 \n4 P8       2020            0.05           0.25                   0.71 \n5 P8       2021            0.05           0.299                  1.08 \n6 P8       2022            0.05           0.29                   0.8  \n# ℹ 3 more variables: DissNitrateNitrite_max &lt;dbl&gt;, DissOrthophos_min &lt;dbl&gt;,\n#   DissOrthophos_max &lt;dbl&gt;",
    "crumbs": [
      "Day 4: 7/18/2024",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Optional Extra Topics</span>"
    ]
  },
  {
    "objectID": "code/Day4_05_Extras.html#using-across",
    "href": "code/Day4_05_Extras.html#using-across",
    "title": "\n8  Optional Extra Topics\n",
    "section": "",
    "text": "8.1.1 Exercise",
    "crumbs": [
      "Day 4: 7/18/2024",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Optional Extra Topics</span>"
    ]
  },
  {
    "objectID": "code/Day4_05_Extras.html#combining-concepts---summarize-and-reshape",
    "href": "code/Day4_05_Extras.html#combining-concepts---summarize-and-reshape",
    "title": "\n8  Optional Extra Topics\n",
    "section": "\n8.2 Combining concepts - Summarize and Reshape",
    "text": "8.2 Combining concepts - Summarize and Reshape\n\ndf_wq %&gt;% \n  mutate(Month = month(Date, label = TRUE)) %&gt;% \n  summarize(Chla = mean(Chla), .by = c(Station, Month)) %&gt;% \n  pivot_wider(names_from = Station, values_from = Chla)\n\n# A tibble: 12 × 3\n   Month    P8    D7\n   &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Jan   0.605  0.67\n 2 Feb   1.17   2.90\n 3 Mar   1.61   4.04\n 4 Jun   4.47   4.44\n 5 Jul   5.31   3.94\n 6 Aug   8.73   3.30\n 7 Sep   4.1    1.89\n 8 Oct   2.42   1.96\n 9 Nov   1.63   1.49\n10 Apr   3.08   2.90\n11 May   3.7    2.3 \n12 Dec   1.27   1.69\n\n\n\n8.2.1 Exercise\nDo the same summarize and reshape as above but calculate annual maximums of TDS for each station\n\nCodedf_wq %&gt;% \n  mutate(Year = year(Date)) %&gt;% \n  summarize(TDS = max(TDS), .by = c(Station, Year)) %&gt;% \n  pivot_wider(names_from = Station, values_from = TDS)",
    "crumbs": [
      "Day 4: 7/18/2024",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Optional Extra Topics</span>"
    ]
  },
  {
    "objectID": "code/Day4_06_Final_Exercise.html",
    "href": "code/Day4_06_Final_Exercise.html",
    "title": "9  Final Exercise",
    "section": "",
    "text": "9.1 Final Course Exercise\nMaybe have people work in pairs, Dave show solution at end (30 min)",
    "crumbs": [
      "Day 4: 7/18/2024",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Final Exercise</span>"
    ]
  },
  {
    "objectID": "code/DatesandTimes.html",
    "href": "code/DatesandTimes.html",
    "title": "Appendix A — Bonus lesson - Dates and Times",
    "section": "",
    "text": "A.1 Dates and Times\nDates and times are one of the most annoying data classes to deal with. There are many different ways of storing date and time information, and it’s easy to get them mixed up. Fortunately, there are a number of tricks that help make things easier, most of which are in the package lubridate. (which is part of tidyverse)\nFor more info, see: https://r4ds.hadley.nz/datetimes.html\nFirst, let’s look at dates. Dates are stored as the number of days since the origin (default origin is 1970-01-01). We can use the today function to get a date with today’s value.\nlibrary(tidyverse)\n\ntoday()\n\n[1] \"2024-07-02\"\n\nas.numeric(today())\n\n[1] 19906\nNow let’s talk about date-times. R automatically stores the dates and times together as the number of seconds since the origin.\nnow()\n\n[1] \"2024-07-02 13:13:37 PDT\"\n\nas.numeric(now())\n\n[1] 1719951218\nNote that R automatically set the time in Pacific Daylight time since that is what the operating system of this computer uses.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Bonus lesson - Dates and Times</span>"
    ]
  },
  {
    "objectID": "code/DatesandTimes.html#datetime-classes",
    "href": "code/DatesandTimes.html#datetime-classes",
    "title": "Appendix A — Bonus lesson - Dates and Times",
    "section": "\nA.2 Date/Time Classes",
    "text": "A.2 Date/Time Classes\nIf you have a list of dates and times that you are importing into R, the read_csv or read_excel functions can usually guess when they are dates, particularly if they are in YYYY-MM-DD format, but sometimes they get confused. They have an especially hard time if they are in a non-standard format, such as MM/DD/YY. In this case, the field will get read in as a character and you have to convert it to a date/time class, usually POSIXct.\nBefore we do that, let’s learn a bit about different types of date/time classes.\nDate - Number of days since origin.\nPOSIXct - Number of seconds since origin. This is the most common format.\nPOSIXlt - List of vectors with components sec, min, hour, mday, mon, and year. You probably won’t use this format very often.\nPOSIXct is more convenient for including in data frames, and POSIXlt is closer to human-readable forms. Both classes may have an attribute tzone, specifying the time zone. See ?DateTimeClasses for details.\nNote: There is no built-in “Time” class, only “DateTime”. Some packages (like hms) have developed ways to deal with times on their own, but it doesn’t come with your base R installation.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Bonus lesson - Dates and Times</span>"
    ]
  },
  {
    "objectID": "code/DatesandTimes.html#converting-from-character-dates",
    "href": "code/DatesandTimes.html#converting-from-character-dates",
    "title": "Appendix A — Bonus lesson - Dates and Times",
    "section": "\nA.3 Converting from character dates",
    "text": "A.3 Converting from character dates\nThe built-in function to convert from characters to dates is strptime\n\n?strptime\n\nTo use this function, we just feed in the date in character form and specify what format it is in. The format syntax is a little annoying, but the documentation for strptime gives you all the options.\n\n#date in character format\ndate1 = \"2/3/2021\"\n\n#Convert it. Little m for month, little d for day, capital Y for four-diget year.\ndate1a = strptime(date1, format = \"%m/%d/%Y\")\ndate1a\n\n[1] \"2021-02-03 PST\"\n\n\n\n#Try a different format. Lowercase y for two-digit year.\n\ndate2 = \"2/3/21\"\ndate2a = strptime(date2, format = \"%m/%d/%y\")\ndate2a\n\n[1] \"2021-02-03 PST\"\n\n\n\n#Now one with a time on it. Note that any spaces or dashes need to be the same in the format call as in your character vector.\n\ndate3 = \"2-3-2021 08:15\"\ndate3a = strptime(date3, format = \"%m-%d-%Y %H:%M\")\ndate3a\n\n[1] \"2021-02-03 08:15:00 PST\"\n\n\nThe format strings are quite annoying, so fortunately the lubridate package has a number of shortcut functions to make converting easier.\n\n?ymd\n\nLet’s try the dates we converted above with these functions.\n\nmdy(date1)\n\n[1] \"2021-02-03\"\n\nmdy(date2)\n\n[1] \"2021-02-03\"\n\nmdy_hm(date3)\n\n[1] \"2021-02-03 08:15:00 UTC\"\n\n\nNote that strptime defaulted the time zone to PDT, whereas mdy_hm defaulted to UTC. It’s always wise to specify your time zone manually to make sure issues don’t come up.\n\nmdy_hm(date3, tz =  \"America/Los_Angeles\")\n\n[1] \"2021-02-03 08:15:00 PST\"\n\n\nNote that when I specified the time zone, I actually specified the location, since we switch time zones with Daylight Savings.\nTo get a complete list of time zone names, see OlsonNames()\n\nOlsonNames()\n\nIf you have a dataset that is collected in California, but doesn’t use Daylight savings, use Etc/GMT+8. GMT (Greenwich Mean Time) doesn’t change with daylight savings, and we are 8 hours ahead.\n\nmdy_hm(date3, tz =  \"Etc/GMT+8\")\n\n[1] \"2021-02-03 08:15:00 -08\"\n\n\nR automatically displays dates and times in Year-Month-Day format. This is the international standard. If you want to change the output format, just use the format function.\n\ndate1a\n\n[1] \"2021-02-03 PST\"\n\nformat(date1a, format = \"%m/%d/%y\")\n\n[1] \"02/03/21\"\n\n\nBut really, why would you want to change the format?\n\nhttps://xkcd.com/1179",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Bonus lesson - Dates and Times</span>"
    ]
  },
  {
    "objectID": "code/DatesandTimes.html#times",
    "href": "code/DatesandTimes.html#times",
    "title": "Appendix A — Bonus lesson - Dates and Times",
    "section": "\nA.4 Times",
    "text": "A.4 Times\nAs noted above, there is no built-in time class. Only date/time classes. So, if we have a bunch of times R will automatically add a date to them.\n\ntimes = c(\"1:20\", \"2:30\", \"3:50\", \"14:00\")\n\ntimes = strptime(times, format = \"%H:%M\")\ntimes\n\n[1] \"2024-07-02 01:20:00 PDT\" \"2024-07-02 02:30:00 PDT\"\n[3] \"2024-07-02 03:50:00 PDT\" \"2024-07-02 14:00:00 PDT\"\n\n\nIt will usually default to today’s date, or sometimes to Dec 31st, 1899. If you have a “Date” and a “Time” column in your dataframe, it’s best to just combine them for manipulation.\n\ndatesandtimes = data.frame(times = c(\"1:20\", \"2:30\", \"3:50\", \"14:00\"),\n                           dates = c(\"2021-01-01\", \"2023-12-01\", \"2011-06-04\", \"2022-10-11\"))\n\nstr(datesandtimes)\n\n'data.frame':   4 obs. of  2 variables:\n $ times: chr  \"1:20\" \"2:30\" \"3:50\" \"14:00\"\n $ dates: chr  \"2021-01-01\" \"2023-12-01\" \"2011-06-04\" \"2022-10-11\"\n\ndatesandtimes = mutate(datesandtimes, \n                       Date = ymd(dates), \n                       Time = strptime(times, format = \"%H:%M\"),\n                       DateTime = ymd_hm(paste(dates, times)))\n\nstr(datesandtimes)\n\n'data.frame':   4 obs. of  5 variables:\n $ times   : chr  \"1:20\" \"2:30\" \"3:50\" \"14:00\"\n $ dates   : chr  \"2021-01-01\" \"2023-12-01\" \"2011-06-04\" \"2022-10-11\"\n $ Date    : Date, format: \"2021-01-01\" \"2023-12-01\" ...\n $ Time    : POSIXlt, format: \"2024-07-02 01:20:00\" \"2024-07-02 02:30:00\" ...\n $ DateTime: POSIXct, format: \"2021-01-01 01:20:00\" \"2023-12-01 02:30:00\" ...\n\n\nIf you do really want to deal with just the time part of a date/time object, use the hms package.\n\nlibrary(hms)\n\nas_hms(times)\n\n01:20:00\n02:30:00\n03:50:00\n14:00:00",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Bonus lesson - Dates and Times</span>"
    ]
  },
  {
    "objectID": "code/DatesandTimes.html#extracting-parts-of-a-datetime-object",
    "href": "code/DatesandTimes.html#extracting-parts-of-a-datetime-object",
    "title": "Appendix A — Bonus lesson - Dates and Times",
    "section": "\nA.5 Extracting parts of a date/time object",
    "text": "A.5 Extracting parts of a date/time object\nLubridate has a lot of really useful thing to take dates and times apart. Like figuring out the month, year, day, etc.\n\n#month (as number or name)\nmonth(date1a)\n\n[1] 2\n\nmonth(date1a, label = TRUE)\n\n[1] Feb\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\n\n#year\nyear(date1a)\n\n[1] 2021\n\n#day of year\nyday(date1a)\n\n[1] 34\n\n#day of week\nwday(date1a, label = T)\n\n[1] Wed\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Bonus lesson - Dates and Times</span>"
    ]
  },
  {
    "objectID": "code/RDefinitions.html",
    "href": "code/RDefinitions.html",
    "title": "Appendix B — Definitions",
    "section": "",
    "text": "Argument- one of possibly several expressions that are passed to a function\nAssignment - Giving a value to a variable. &lt;- is known as the “assignment operator”.\nComment: Text written in a script that is not treated as code to be run, but rather as text that describes what the code is doing. These are usually short notes, beginning with a #\nConsole - Place you run your code. It prints all the inputs and outputs - but then it’s gone!\nComprehensive R Archive Network (CRAN) - A public repository of R packages\nData frame - A two-dimensional data structure for storing tabular data in memory. Rows represent records and columns represent variables.\nEnvironment - A collection of functions, objects, and variables that are available for you to work with.\nFunction - A code block which gathers a sequence of operations into a whole, preserving it for ongoing use by defining a set of tasks that takes zero or more required and optional arguments as inputs and returns expected outputs (return values), if any. Functions enable repeating these defined tasks with one command, known as a function call.\nGUI - “Graphical User Interface” - anything you can point-and-click to get what you want. This is in contrast to the “command line” where you have to write out what you want.\nScript - Text file with code you want to run\nProject - Set of scripts, data, and outputs that are associated with a working directory and are related to each other using an .Proj file.\nPackage - A collection of code, data, and documentation that can be distributed and re-used. Also referred to in some languages as a library or module.\nPipe operator: The %&gt;% used to make the output of one function the input of the next. Piping works particularly well with Tidyverse packages.\nObject - A data set, a variable, plot, or more formally, almost everything in R. If it has a mode, it is an object. Includes data frames, vectors, matrices, arrays, lists and functions.\nTidyverse - A collection of R packages for operating on tabular data in consistent ways.\nVector - A list of items of the same type (e.g., a list of numbers or words).\nWorking directory - The folder that contains all the scripts and data you are working with.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Definitions</span>"
    ]
  },
  {
    "objectID": "code/Resources.html",
    "href": "code/Resources.html",
    "title": "Appendix C — Useful Resources",
    "section": "",
    "text": "R For Data Science - a must-read e-book for how to handle data in R. https://r4ds.hadley.nz\nCheetsheets for popular R packages. https://rstudio.github.io/cheatsheets\nIEP Data Science Project Workteam homepage. https://interagencyecologicalprogram.github.io/DataScience/\nRSeek - Google for R related websites. https://rseek.org/\nChat GPT and other generative AI apps can help you write code. https://chatgpt.com/\nThe R Graph Gallery - get ideas for new types of graphs, and the code to make them. https://r-graph-gallery.com/\nMore information on the tidyverse packages. https://www.tidyverse.org/",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Useful Resources</span>"
    ]
  },
  {
    "objectID": "code/Day2_DataOrg.html#read-in-data",
    "href": "code/Day2_DataOrg.html#read-in-data",
    "title": "\n3  Data Manipulation\n",
    "section": "\n3.3 Read in Data",
    "text": "3.3 Read in Data\nNext, we must import our data. The common function for this is read_csv from readr (which is nested in tidyverse). For our demonstrations, we will use the WQ_P8D7.csv file housed in the data folder.\nWhen importing data, we must specify the filepath where it’s housed. There are multiple ways to do this. We could hard-code in the path, which is called the absolute path:\n\ndf_wq &lt;- read_csv('C:/R/IntrotoR/data/WQ_P8D7.csv')\n\nError: 'C:/R/IntrotoR/data/WQ_P8D7.csv' does not exist.\n\n\nHowever, this code is very specific and will break when used on other computers. If we instead house data in a Project, we can make use of relative filepaths. These are ideal because anyone who uses the Project can run the code:\n\ndf_wq &lt;- read_csv('data/WQ_P8D7.csv')\n\nIf you received an error here, this is because your Rmd files are not being evaluated at the Project level. One way to fix this is to change your options in Tools &gt; Global Options &gt; R Markdown &gt; evaluate chunks in directory to Project.\nYou can also use the here package instead:\n\nlibrary(here)\n\ndf_wq &lt;- read_csv(here('data/WQ_P8D7.csv'))\n\nWe now have a dataframe object called df_wq. We can use head to see what this dataframe looks like:\n\nhead(df_wq)\n\n# A tibble: 6 × 20\n  Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 P8      2020-01-16  0.64       0.5             98        0.15\n2 D7      2020-01-22  0.67       0.87            82        0.21\n3 P8      2020-02-14  1.46       0.69            81        0.25\n4 D7      2020-02-20  2.15       0.5             86        0.14\n5 P8      2020-03-03  1.4        0.56            80        0.11\n6 D7      2020-03-06  1.89       1.13            93        0.22\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\nAnd glimpse to see information about the columns:\n\nglimpse(df_wq)\n\nRows: 62\nColumns: 20\n$ Station            &lt;chr&gt; \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8…\n$ Date               &lt;date&gt; 2020-01-16, 2020-01-22, 2020-02-14, 2020-02-20, 20…\n$ Chla               &lt;dbl&gt; 0.64, 0.67, 1.46, 2.15, 1.40, 1.89, 4.73, 1.74, 6.4…\n$ Pheophytin         &lt;dbl&gt; 0.50, 0.87, 0.69, 0.50, 0.56, 1.13, 1.25, 0.89, 0.8…\n$ TotAlkalinity      &lt;dbl&gt; 98.0, 82.0, 81.0, 86.0, 80.0, 93.0, 59.0, 78.0, 63.…\n$ DissAmmonia        &lt;dbl&gt; 0.150, 0.210, 0.250, 0.140, 0.110, 0.220, 0.050, 0.…\n$ DissNitrateNitrite &lt;dbl&gt; 2.800, 0.490, 1.700, 0.480, 1.600, 0.380, 1.070, 0.…\n$ DOC                &lt;dbl&gt; 3.90, 0.27, 2.80, 0.39, 2.00, 0.19, 2.80, 1.20, 3.1…\n$ TOC                &lt;dbl&gt; 4.10, 0.32, 2.50, 0.41, 2.10, 0.20, 2.80, 1.20, 3.1…\n$ DON                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 0.30, 0.20, 0.30, 0.10, 0.5…\n$ TotPhos            &lt;dbl&gt; 0.310, 0.082, 0.130, 0.130, 0.190, 0.100, 0.188, 0.…\n$ DissOrthophos      &lt;dbl&gt; 0.200, 0.071, 0.130, 0.065, 0.140, 0.082, 0.177, 0.…\n$ TDS                &lt;dbl&gt; 380, 9500, 340, 5800, 290, 8700, 280, 7760, 227, 11…\n$ TSS                &lt;dbl&gt; 8.9, 38.0, 2.2, 18.0, 1.4, 28.0, 6.6, 35.6, 5.3, 23…\n$ TKN                &lt;dbl&gt; 0.520, 0.480, 0.430, 0.250, 0.400, 0.200, 0.400, 0.…\n$ Depth              &lt;dbl&gt; 28.9, 18.8, 39.0, 7.1, 39.0, 7.2, 37.1, 5.2, 36.7, …\n$ Secchi             &lt;dbl&gt; 116, 30, 212, 52, 340, 48, 100, 40, 160, 44, 120, 6…\n$ Microcystis        &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 3, 2, 3, 2, 4, 2, 3, 2, 2, 1, 1, …\n$ SpCndSurface       &lt;dbl&gt; 667, 15532, 647, 11369, 530, 16257, 503, 12946, 404…\n$ WTSurface          &lt;dbl&gt; 9.67, 9.97, 11.09, 12.51, 13.97, 13.81, 23.46, 21.1…",
    "crumbs": [
      "Day 2: 7/11/2024",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulation</span>"
    ]
  },
  {
    "objectID": "code/Day2_DataOrg.html#subsetting",
    "href": "code/Day2_DataOrg.html#subsetting",
    "title": "\n3  Data Manipulation\n",
    "section": "\n3.4 Subsetting",
    "text": "3.4 Subsetting\nLets talk a bit about the structure of the data frame. Dataframes are 2-dimensional objects (row x column). Every entry in a dataframe has a unique index that’s defined by which row x column it’s in. Since we rarely want to work on the entire dataframe at once, we can use these indices to subset our data.\nFor example, if I want to look at the value in the 1st row of the 2nd column:\n\ndf_wq[1,2]\n\n# A tibble: 1 × 1\n  Date      \n  &lt;date&gt;    \n1 2020-01-16\n\n\nor, perhaps, the 2nd row of the 1st column:\n\ndf_wq[2,1]\n\n# A tibble: 1 × 1\n  Station\n  &lt;chr&gt;  \n1 D7     \n\n\nWe can also access an entire row or column at once:\n\ndf_wq[1,] # entire row\n\n# A tibble: 1 × 20\n  Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 P8      2020-01-16  0.64        0.5            98        0.15\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\ndf_wq[,1] # entire column\n\n# A tibble: 62 × 1\n   Station\n   &lt;chr&gt;  \n 1 P8     \n 2 D7     \n 3 P8     \n 4 D7     \n 5 P8     \n 6 D7     \n 7 P8     \n 8 D7     \n 9 P8     \n10 D7     \n# ℹ 52 more rows\n\n\nYou can also subset multiple columns/rows at once by using a :\n\ndf_wq[,2:4] # all rows, 2-4th columns\n\n# A tibble: 62 × 3\n   Date        Chla Pheophytin\n   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 2020-01-16  0.64       0.5 \n 2 2020-01-22  0.67       0.87\n 3 2020-02-14  1.46       0.69\n 4 2020-02-20  2.15       0.5 \n 5 2020-03-03  1.4        0.56\n 6 2020-03-06  1.89       1.13\n 7 2020-06-11  4.73       1.25\n 8 2020-06-17  1.74       0.89\n 9 2020-07-13  6.4        0.88\n10 2020-07-16  2.79       0.85\n# ℹ 52 more rows\n\n\n\n3.4.1 Subset by Column Name\nSubsetting is very powerful, but one issue is – by access values by their numerical index – we can get confused about what we’re accessing. For example, if I wanted to work with DissAmmonia data, I would have to first know that it’s the 4th column in my dataframe. That can get unwieldy with complex datasets.\nInstead, we can use the column header to call a particular column:\n\ndf_wq['DissAmmonia']\n\n# A tibble: 62 × 1\n   DissAmmonia\n         &lt;dbl&gt;\n 1        0.15\n 2        0.21\n 3        0.25\n 4        0.14\n 5        0.11\n 6        0.22\n 7        0.05\n 8        0.05\n 9        0.05\n10        0.05\n# ℹ 52 more rows\n\n\n\nstr(df_wq['DissAmmonia'])\n\ntibble [62 × 1] (S3: tbl_df/tbl/data.frame)\n $ DissAmmonia: num [1:62] 0.15 0.21 0.25 0.14 0.11 0.22 0.05 0.05 0.05 0.05 ...\n\n\nThis returns a tibble that only contains the relevant column.\nWe can also call the column as a vector (this is the more common syntax):\n\ndf_wq$DissAmmonia\n\n [1] 0.150 0.210 0.250 0.140 0.110 0.220 0.050 0.050 0.050 0.050 0.050 0.050\n[13] 0.062 0.060 0.050 0.050 0.050 0.123 0.299 0.135 0.063 0.078 0.050 0.093\n[25] 0.056 0.058 0.050 0.050 0.050 0.050 0.069 0.050 0.069 0.073 0.118 0.186\n[37] 0.090 0.192 0.113 0.107 0.053 0.106 0.086 0.050 0.081 0.060 0.050 0.056\n[49] 0.128 0.145 0.290 0.145 0.070 0.109 0.068 0.050 0.050 0.050 0.061 0.070\n[61] 0.061 0.168\n\n\n\nstr(df_wq$DissAmmonia)\n\n num [1:62] 0.15 0.21 0.25 0.14 0.11 0.22 0.05 0.05 0.05 0.05 ...\n\n\nTo select multiple columns by name, we use our : technique within the select function from the dplyr package (in tidyverse):\n\ndf_wq %&gt;% select(Station:Pheophytin)\n\n# A tibble: 62 × 4\n   Station Date        Chla Pheophytin\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 P8      2020-01-16  0.64       0.5 \n 2 D7      2020-01-22  0.67       0.87\n 3 P8      2020-02-14  1.46       0.69\n 4 D7      2020-02-20  2.15       0.5 \n 5 P8      2020-03-03  1.4        0.56\n 6 D7      2020-03-06  1.89       1.13\n 7 P8      2020-06-11  4.73       1.25\n 8 D7      2020-06-17  1.74       0.89\n 9 P8      2020-07-13  6.4        0.88\n10 D7      2020-07-16  2.79       0.85\n# ℹ 52 more rows\n\n\nIf this is the only data I want to work with, I can store this as a unique object:\n\ndf_chlpheo &lt;- df_wq %&gt;% select(Station:Pheophytin)\n\n\nglimpse(df_chlpheo)\n\nRows: 62\nColumns: 4\n$ Station    &lt;chr&gt; \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\", \"P8\", \"D7\",…\n$ Date       &lt;date&gt; 2020-01-16, 2020-01-22, 2020-02-14, 2020-02-20, 2020-03-03…\n$ Chla       &lt;dbl&gt; 0.64, 0.67, 1.46, 2.15, 1.40, 1.89, 4.73, 1.74, 6.40, 2.79,…\n$ Pheophytin &lt;dbl&gt; 0.50, 0.87, 0.69, 0.50, 0.56, 1.13, 1.25, 0.89, 0.88, 0.85,…\n\n\n\n3.4.1.1 Aside: Tidyverse Pipes\nYou’ll notice I used some new syntax there, namely, the %&gt;%. This is called the pipe operator, Operators are functions that allows one to perform operations on other functions/variables. The pipe operator specifically allows you to chain together tidyverse commands.\nTherefore, instead of writing the above code like this:\n\nselect(df_wq, Station:Pheophytin)\n\n# A tibble: 62 × 4\n   Station Date        Chla Pheophytin\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 P8      2020-01-16  0.64       0.5 \n 2 D7      2020-01-22  0.67       0.87\n 3 P8      2020-02-14  1.46       0.69\n 4 D7      2020-02-20  2.15       0.5 \n 5 P8      2020-03-03  1.4        0.56\n 6 D7      2020-03-06  1.89       1.13\n 7 P8      2020-06-11  4.73       1.25\n 8 D7      2020-06-17  1.74       0.89\n 9 P8      2020-07-13  6.4        0.88\n10 D7      2020-07-16  2.79       0.85\n# ℹ 52 more rows\n\n\nFor clarity, I can pipe the dataframe into the select function:\n\ndf_wq %&gt;% select(Station:Pheophytin)\n\n# A tibble: 62 × 4\n   Station Date        Chla Pheophytin\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 P8      2020-01-16  0.64       0.5 \n 2 D7      2020-01-22  0.67       0.87\n 3 P8      2020-02-14  1.46       0.69\n 4 D7      2020-02-20  2.15       0.5 \n 5 P8      2020-03-03  1.4        0.56\n 6 D7      2020-03-06  1.89       1.13\n 7 P8      2020-06-11  4.73       1.25\n 8 D7      2020-06-17  1.74       0.89\n 9 P8      2020-07-13  6.4        0.88\n10 D7      2020-07-16  2.79       0.85\n# ℹ 52 more rows\n\n\n\n3.4.2 Subset By Row Values\nAnother common goal is to subset by particular row values – say, only a given station, date range, or analyte value range. Tidyverse also has functions for this! Specifically, we use filter from the dplyr package:\n\ndf_p8 &lt;- df_wq %&gt;% filter(Station == 'P8')\n\n\nunique(df_p8$Station)\n\n[1] \"P8\"\n\n\n\n3.4.3 Aside: Logical Operators\n\n3.4.3.1 equality (==) and negate equality (!=)\nNote we used another new symbol: ==. This is the equality operator, a type of logical operator. Logical operators allow us to dictate what our code does via logical statements.\nEquality, as we saw above, tells the code to find all values from the right-hand side that are equal to the left-hand side.\nNegate does the opposite; it gives us the values that do not match. Here, we apply it to the equality operator, but note that ! is the general negate operator; it can be applied to any logical statement.\n\ndf_notp8 &lt;- df_wq %&gt;% filter(Station != 'P8')\n\n\nunique(df_notp8$Station)\n\n[1] \"D7\"\n\n\n\n3.4.3.2 and (&) and or (|)\nSometimes, we want to filter by multiple commands at once. We can use this using the logical operators and (&) or or (’|`):\n\ndf_wq %&gt;% filter(Station == 'P8' & Date == '2020-01-16')\n\n# A tibble: 1 × 20\n  Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 P8      2020-01-16  0.64        0.5            98        0.15\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\ndf_wq %&gt;% filter(Date == '2020-01-16' | Date == '2020-01-22')\n\n# A tibble: 2 × 20\n  Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 P8      2020-01-16  0.64       0.5             98        0.15\n2 D7      2020-01-22  0.67       0.87            82        0.21\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\n3.4.3.3 less than &lt; and greater than &gt;\n\nSometimes, we want all values above or below:\n\ndf_wq %&gt;% filter(Date &gt;= '2020-02-01')\n\n# A tibble: 60 × 20\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2020-02-14  1.46       0.69            81        0.25\n 2 D7      2020-02-20  2.15       0.5             86        0.14\n 3 P8      2020-03-03  1.4        0.56            80        0.11\n 4 D7      2020-03-06  1.89       1.13            93        0.22\n 5 P8      2020-06-11  4.73       1.25            59        0.05\n 6 D7      2020-06-17  1.74       0.89            78        0.05\n 7 P8      2020-07-13  6.4        0.88            63        0.05\n 8 D7      2020-07-16  2.79       0.85            80        0.05\n 9 P8      2020-08-11 16.5        1.41            65        0.05\n10 D7      2020-08-17  0.5        6.13            83        0.05\n# ℹ 50 more rows\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\ndf_wq %&gt;% filter(Date &lt;= '2020-06-30')\n\n# A tibble: 8 × 20\n  Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 P8      2020-01-16  0.64       0.5             98        0.15\n2 D7      2020-01-22  0.67       0.87            82        0.21\n3 P8      2020-02-14  1.46       0.69            81        0.25\n4 D7      2020-02-20  2.15       0.5             86        0.14\n5 P8      2020-03-03  1.4        0.56            80        0.11\n6 D7      2020-03-06  1.89       1.13            93        0.22\n7 P8      2020-06-11  4.73       1.25            59        0.05\n8 D7      2020-06-17  1.74       0.89            78        0.05\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\ndf_wq %&gt;% filter(!(Date &gt;= '2020-06-30')) # same thing but using negate\n\n# A tibble: 8 × 20\n  Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 P8      2020-01-16  0.64       0.5             98        0.15\n2 D7      2020-01-22  0.67       0.87            82        0.21\n3 P8      2020-02-14  1.46       0.69            81        0.25\n4 D7      2020-02-20  2.15       0.5             86        0.14\n5 P8      2020-03-03  1.4        0.56            80        0.11\n6 D7      2020-03-06  1.89       1.13            93        0.22\n7 P8      2020-06-11  4.73       1.25            59        0.05\n8 D7      2020-06-17  1.74       0.89            78        0.05\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\nWhat if we want data in between two dates? We can use the and (&) operator!\n\ndf_wq %&gt;% filter(Date &gt;= '2020-02-01' & Date &lt;= '2020-06-30')\n\n# A tibble: 6 × 20\n  Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 P8      2020-02-14  1.46       0.69            81        0.25\n2 D7      2020-02-20  2.15       0.5             86        0.14\n3 P8      2020-03-03  1.4        0.56            80        0.11\n4 D7      2020-03-06  1.89       1.13            93        0.22\n5 P8      2020-06-11  4.73       1.25            59        0.05\n6 D7      2020-06-17  1.74       0.89            78        0.05\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\n3.4.3.4 in (%in%)\nWhat if we wanted to subset by five specific dates? We could string together multiple or (|) commands, but that can become unwieldy to write.\nWhat if I instead had a vector of those five specific dates? Then I could subset by all the data in my dataset that matches one of the values in that vector.\nThis is what the %in% function does:\n\ndf_wq %&gt;% filter(Date %in% c('2020-02-14','2020-03-06','2020-06-11','2021-03-05','2021-04-05'))\n\n# A tibble: 5 × 20\n  Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 P8      2020-02-14  1.46       0.69            81       0.25 \n2 D7      2020-03-06  1.89       1.13            93       0.22 \n3 P8      2020-06-11  4.73       1.25            59       0.05 \n4 P8      2021-03-05  1.56       0.5            103       0.299\n5 P8      2021-04-05  2.62       1.1            116       0.063\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\n3.4.4 Aside: the lubridate package\nWhat if I want to subset all values in a given year? If I had a vector of all the years in my dataset, then I could simply use %in%! But how would I get that vector?\nThe lubridate package allows you to manipulate dates. Since dates are complicated in R, we won’t go into too much detail. However, a few useful functions are day, month, and year, which returns the days, months, and years (as vectors) from a vector of dates:\nOriginal:\n\ndf_wq$Date\n\n [1] \"2020-01-16\" \"2020-01-22\" \"2020-02-14\" \"2020-02-20\" \"2020-03-03\"\n [6] \"2020-03-06\" \"2020-06-11\" \"2020-06-17\" \"2020-07-13\" \"2020-07-16\"\n[11] \"2020-08-11\" \"2020-08-17\" \"2020-09-09\" \"2020-09-24\" \"2020-10-08\"\n[16] \"2020-10-13\" \"2020-11-06\" \"2020-11-12\" \"2021-03-05\" \"2021-03-10\"\n[21] \"2021-04-05\" \"2021-04-08\" \"2021-05-05\" \"2021-05-10\" \"2021-06-03\"\n[26] \"2021-06-08\" \"2021-07-16\" \"2021-07-21\" \"2021-08-16\" \"2021-08-19\"\n[31] \"2021-09-10\" \"2021-09-16\" \"2021-10-13\" \"2021-10-18\" \"2021-11-10\"\n[36] \"2021-11-16\" \"2021-12-10\" \"2021-12-15\" \"2022-01-12\" \"2022-02-14\"\n[41] \"2022-03-16\" \"2022-04-27\" \"2022-05-27\" \"2022-06-27\" \"2022-07-25\"\n[46] \"2022-08-22\" \"2022-09-20\" \"2022-10-19\" \"2022-11-18\" \"2022-12-19\"\n[51] \"2022-01-07\" \"2022-02-09\" \"2022-03-11\" \"2022-04-22\" \"2022-05-23\"\n[56] \"2022-06-22\" \"2022-07-20\" \"2022-08-17\" \"2022-09-15\" \"2022-10-14\"\n[61] \"2022-11-15\" \"2022-12-14\"\n\n\nDays:\n\nday(df_wq$Date)\n\n [1] 16 22 14 20  3  6 11 17 13 16 11 17  9 24  8 13  6 12  5 10  5  8  5 10  3\n[26]  8 16 21 16 19 10 16 13 18 10 16 10 15 12 14 16 27 27 27 25 22 20 19 18 19\n[51]  7  9 11 22 23 22 20 17 15 14 15 14\n\n\nMonths:\n\nmonth(df_wq$Date)\n\n [1]  1  1  2  2  3  3  6  6  7  7  8  8  9  9 10 10 11 11  3  3  4  4  5  5  6\n[26]  6  7  7  8  8  9  9 10 10 11 11 12 12  1  2  3  4  5  6  7  8  9 10 11 12\n[51]  1  2  3  4  5  6  7  8  9 10 11 12\n\n\nYears:\n\nyear(df_wq$Date)\n\n [1] 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020\n[16] 2020 2020 2020 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021\n[31] 2021 2021 2021 2021 2021 2021 2021 2021 2022 2022 2022 2022 2022 2022 2022\n[46] 2022 2022 2022 2022 2022 2022 2022 2022 2022 2022 2022 2022 2022 2022 2022\n[61] 2022 2022\n\n\nOne use for these functions is subsetting! Say we want all entries from the year 2021:\n\ndf_wq %&gt;% filter(year(Date) %in% '2021')\n\n# A tibble: 20 × 20\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2021-03-05  1.56       0.5          103         0.299\n 2 D7      2021-03-10  4.77       0.5           97.9       0.135\n 3 P8      2021-04-05  2.62       1.1          116         0.063\n 4 D7      2021-04-08  3.28       0.83          93.9       0.078\n 5 P8      2021-05-05  4.73       1.48          89.9       0.05 \n 6 D7      2021-05-10  1.85       0.55         100         0.093\n 7 P8      2021-06-03  4.39       0.5           78.1       0.056\n 8 D7      2021-06-08  4.21       1.2           96.8       0.058\n 9 P8      2021-07-16  4.3        2.28          49.2       0.05 \n10 D7      2021-07-21  6.54       1.15          93.4       0.05 \n11 P8      2021-08-16  5.56       1.2           46.4       0.05 \n12 D7      2021-08-19  6.76       4.03          91.1       0.05 \n13 P8      2021-09-10  3.85       1.22          57.5       0.069\n14 D7      2021-09-16  2.74       1.32          91.5       0.05 \n15 P8      2021-10-13  1.97       0.57          74.9       0.069\n16 D7      2021-10-18  2.95       2.86          94.9       0.073\n17 P8      2021-11-10  1.25       0.92          59.8       0.118\n18 D7      2021-11-16  1.52       1.38          85.6       0.186\n19 P8      2021-12-10  1.52       0.7           79.4       0.09 \n20 D7      2021-12-15  1.17       1.55          91.5       0.192\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\n# same thing but using negate\ndf_wq %&gt;% filter(\n  !(year(Date) %in% c('2020','2022'))\n  )\n\n# A tibble: 20 × 20\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2021-03-05  1.56       0.5          103         0.299\n 2 D7      2021-03-10  4.77       0.5           97.9       0.135\n 3 P8      2021-04-05  2.62       1.1          116         0.063\n 4 D7      2021-04-08  3.28       0.83          93.9       0.078\n 5 P8      2021-05-05  4.73       1.48          89.9       0.05 \n 6 D7      2021-05-10  1.85       0.55         100         0.093\n 7 P8      2021-06-03  4.39       0.5           78.1       0.056\n 8 D7      2021-06-08  4.21       1.2           96.8       0.058\n 9 P8      2021-07-16  4.3        2.28          49.2       0.05 \n10 D7      2021-07-21  6.54       1.15          93.4       0.05 \n11 P8      2021-08-16  5.56       1.2           46.4       0.05 \n12 D7      2021-08-19  6.76       4.03          91.1       0.05 \n13 P8      2021-09-10  3.85       1.22          57.5       0.069\n14 D7      2021-09-16  2.74       1.32          91.5       0.05 \n15 P8      2021-10-13  1.97       0.57          74.9       0.069\n16 D7      2021-10-18  2.95       2.86          94.9       0.073\n17 P8      2021-11-10  1.25       0.92          59.8       0.118\n18 D7      2021-11-16  1.52       1.38          85.6       0.186\n19 P8      2021-12-10  1.52       0.7           79.4       0.09 \n20 D7      2021-12-15  1.17       1.55          91.5       0.192\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\n3.4.5 Exercise\nIn one filter function, how would I select data that’s either before 2020-02-28 or after 2022-11-01?\n\nCodedf_wq %&gt;% filter(Date &lt;= '2020-02-28' | Date &gt;= '2022-11-01')\n\n\n\n3.4.6 Subset by Column and Row\nUsing our knowledge of pipes, it’s easy to subset by column and row at the same time!\n\ndf_wq %&gt;% filter(Date == '2020-01-16' | Date == '2020-01-22') %&gt;% select(Station:Pheophytin)\n\n# A tibble: 2 × 4\n  Station Date        Chla Pheophytin\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 P8      2020-01-16  0.64       0.5 \n2 D7      2020-01-22  0.67       0.87\n\n\n\n3.4.6.1 Aside: Formatting Code\nNotice that above all the code is on the same line. This can be difficult to read. You can get around this by formatting your code. Personally, I like having different functions on different lines:\n\ndf_wq %&gt;%\n  filter(Date == '2020-01-16' | Date == '2020-01-22') %&gt;%\n  select(Station:Pheophytin)\n\n# A tibble: 2 × 4\n  Station Date        Chla Pheophytin\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 P8      2020-01-16  0.64       0.5 \n2 D7      2020-01-22  0.67       0.87\n\n\nYou can also use ctrl+shift+A to auto-format code! Note that it looks different from above; this is fine. As long as you deem the code readable (and it works), you’re set.\n\n# original\ndf_wq %&gt;% filter(Date == '2020-01-16' | Date == '2020-01-22') %&gt;% select(Station:Pheophytin)\n\n# A tibble: 2 × 4\n  Station Date        Chla Pheophytin\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 P8      2020-01-16  0.64       0.5 \n2 D7      2020-01-22  0.67       0.87\n\n# ctrl+shift+A\ndf_wq %&gt;% filter(Date == '2020-01-16' |\n                   Date == '2020-01-22') %&gt;% select(Station:Pheophytin)\n\n# A tibble: 2 × 4\n  Station Date        Chla Pheophytin\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 P8      2020-01-16  0.64       0.5 \n2 D7      2020-01-22  0.67       0.87\n\n\n\n3.4.7 Subset NA\nThere’s one more type of subset that we’ll cover today. This is selecting data that is NA.\nNA is a logical constant of length 1 which contains a missing value indicator:\n\ntypeof(NA) # NA\n\n[1] \"logical\"\n\ntypeof('NA') # not the same\n\n[1] \"character\"\n\n\nSometimes, we want to select only NA data, or omit it entirely. Looking at the Chla column, we see that there are NAs:\n\nunique(df_wq$DON)\n\n [1]   NA 0.30 0.20 0.10 0.50 0.22 0.19 0.11 0.53 0.13 0.46 0.25 0.37 0.29 0.17\n[16] 0.24 0.27 0.21 0.35 0.12 0.18 0.16 1.07 0.33 0.40 0.44 0.43 0.42 0.38\n\n\nA quicker to check this is the is.na function:\n\nis.na(df_wq$DON)\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[61] FALSE FALSE\n\n\nThis returns a logical vector. If I want to subset by this, I can use the filter function:\n\ndf_wq %&gt;%\n  filter(is.na(df_wq$DON)) %&gt;%\n  select(Station, Date, DON)\n\n# A tibble: 6 × 3\n  Station Date         DON\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;\n1 P8      2020-01-16    NA\n2 D7      2020-01-22    NA\n3 P8      2020-02-14    NA\n4 D7      2020-02-20    NA\n5 P8      2020-03-03    NA\n6 D7      2020-03-06    NA\n\n\nQuestion: What operator would I use if I want all data except NAs (hint: I want to negate NA)\nChallenge Exercise: How would I write this statement? (Hint: examples are above)\n\nCodedf_wq %&gt;%\n  filter(!is.na(df_wq$DON)) %&gt;% # use the ! operator before the function to negate it\n  select(Station, Date, DON)",
    "crumbs": [
      "Day 2: 7/11/2024",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulation</span>"
    ]
  },
  {
    "objectID": "code/Day2_DataOrg.html#mutate-function",
    "href": "code/Day2_DataOrg.html#mutate-function",
    "title": "\n3  Data Manipulation\n",
    "section": "\n3.5 Mutate Function",
    "text": "3.5 Mutate Function\n\n3.5.1 New Columns\nSometimes, we want to modify our already existing columns, or even add new ones. This is where the mutate function from the dplyr package comes in.\nWith mutate, we can add in new columns:\n\nhead(df_notp8)\n\n# A tibble: 6 × 20\n  Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n  &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n1 D7      2020-01-22  0.67       0.87            82        0.21\n2 D7      2020-02-20  2.15       0.5             86        0.14\n3 D7      2020-03-06  1.89       1.13            93        0.22\n4 D7      2020-06-17  1.74       0.89            78        0.05\n5 D7      2020-07-16  2.79       0.85            80        0.05\n6 D7      2020-08-17  0.5        6.13            83        0.05\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\ndf_wq %&gt;%\n  mutate(Lab = 'BSA')\n\n# A tibble: 62 × 21\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2020-01-16  0.64       0.5             98        0.15\n 2 D7      2020-01-22  0.67       0.87            82        0.21\n 3 P8      2020-02-14  1.46       0.69            81        0.25\n 4 D7      2020-02-20  2.15       0.5             86        0.14\n 5 P8      2020-03-03  1.4        0.56            80        0.11\n 6 D7      2020-03-06  1.89       1.13            93        0.22\n 7 P8      2020-06-11  4.73       1.25            59        0.05\n 8 D7      2020-06-17  1.74       0.89            78        0.05\n 9 P8      2020-07-13  6.4        0.88            63        0.05\n10 D7      2020-07-16  2.79       0.85            80        0.05\n# ℹ 52 more rows\n# ℹ 15 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;, Lab &lt;chr&gt;\n\n\nWe can even add columns that are combinations of other ones:\n\ndf_wq %&gt;%\n  mutate(chlpheo = Chla+Pheophytin)\n\n# A tibble: 62 × 21\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2020-01-16  0.64       0.5             98        0.15\n 2 D7      2020-01-22  0.67       0.87            82        0.21\n 3 P8      2020-02-14  1.46       0.69            81        0.25\n 4 D7      2020-02-20  2.15       0.5             86        0.14\n 5 P8      2020-03-03  1.4        0.56            80        0.11\n 6 D7      2020-03-06  1.89       1.13            93        0.22\n 7 P8      2020-06-11  4.73       1.25            59        0.05\n 8 D7      2020-06-17  1.74       0.89            78        0.05\n 9 P8      2020-07-13  6.4        0.88            63        0.05\n10 D7      2020-07-16  2.79       0.85            80        0.05\n# ℹ 52 more rows\n# ℹ 15 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;, chlpheo &lt;dbl&gt;\n\n\n\ndf_wq %&gt;%\n  mutate(statdate = paste(Station,Date,sep = '_'))\n\n# A tibble: 62 × 21\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2020-01-16  0.64       0.5             98        0.15\n 2 D7      2020-01-22  0.67       0.87            82        0.21\n 3 P8      2020-02-14  1.46       0.69            81        0.25\n 4 D7      2020-02-20  2.15       0.5             86        0.14\n 5 P8      2020-03-03  1.4        0.56            80        0.11\n 6 D7      2020-03-06  1.89       1.13            93        0.22\n 7 P8      2020-06-11  4.73       1.25            59        0.05\n 8 D7      2020-06-17  1.74       0.89            78        0.05\n 9 P8      2020-07-13  6.4        0.88            63        0.05\n10 D7      2020-07-16  2.79       0.85            80        0.05\n# ℹ 52 more rows\n# ℹ 15 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;, statdate &lt;chr&gt;\n\n\n\n3.5.1.1 Aside: Relocate Columns\nSometimes, we want to re-arrange our column order. For example, with our new Lab column, we might want that in the beginning with the other metadata. Here, we use the relocate function:\n\ndf_wq %&gt;%\n  mutate(Lab = 'BSA') %&gt;%\n  relocate(Lab, .after = Date)\n\n# A tibble: 62 × 21\n   Station Date       Lab    Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2020-01-16 BSA    0.64       0.5             98        0.15\n 2 D7      2020-01-22 BSA    0.67       0.87            82        0.21\n 3 P8      2020-02-14 BSA    1.46       0.69            81        0.25\n 4 D7      2020-02-20 BSA    2.15       0.5             86        0.14\n 5 P8      2020-03-03 BSA    1.4        0.56            80        0.11\n 6 D7      2020-03-06 BSA    1.89       1.13            93        0.22\n 7 P8      2020-06-11 BSA    4.73       1.25            59        0.05\n 8 D7      2020-06-17 BSA    1.74       0.89            78        0.05\n 9 P8      2020-07-13 BSA    6.4        0.88            63        0.05\n10 D7      2020-07-16 BSA    2.79       0.85            80        0.05\n# ℹ 52 more rows\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\n3.5.2 Existing Columns\nWe can also use mutate to modify existing columns\n\ndf_wq %&gt;%\n  mutate(Chla = Chla+20)\n\n# A tibble: 62 × 20\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2020-01-16  20.6       0.5             98        0.15\n 2 D7      2020-01-22  20.7       0.87            82        0.21\n 3 P8      2020-02-14  21.5       0.69            81        0.25\n 4 D7      2020-02-20  22.2       0.5             86        0.14\n 5 P8      2020-03-03  21.4       0.56            80        0.11\n 6 D7      2020-03-06  21.9       1.13            93        0.22\n 7 P8      2020-06-11  24.7       1.25            59        0.05\n 8 D7      2020-06-17  21.7       0.89            78        0.05\n 9 P8      2020-07-13  26.4       0.88            63        0.05\n10 D7      2020-07-16  22.8       0.85            80        0.05\n# ℹ 52 more rows\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\nWe can even change types! This is useful if, say, you have character column that should be numeric.\n\ndf_wq %&gt;%\n  mutate(Chla = as.numeric(Chla),\n         Pheophytin = as.numeric(Pheophytin))\n\n# A tibble: 62 × 20\n   Station Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8      2020-01-16  0.64       0.5             98        0.15\n 2 D7      2020-01-22  0.67       0.87            82        0.21\n 3 P8      2020-02-14  1.46       0.69            81        0.25\n 4 D7      2020-02-20  2.15       0.5             86        0.14\n 5 P8      2020-03-03  1.4        0.56            80        0.11\n 6 D7      2020-03-06  1.89       1.13            93        0.22\n 7 P8      2020-06-11  4.73       1.25            59        0.05\n 8 D7      2020-06-17  1.74       0.89            78        0.05\n 9 P8      2020-07-13  6.4        0.88            63        0.05\n10 D7      2020-07-16  2.79       0.85            80        0.05\n# ℹ 52 more rows\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;\n\n\n\n3.5.2.1 Aside: Case When\nWhat if we only want to modify certain data in a column? Say, we want to add 20 to all Chla values but only for P8.\nThis can be done using the case_when function instead a mutate function:\n\ndf_wq %&gt;%\n  mutate(\n    Chla =\n      case_when(Station == 'P8' ~ Chla + 20, # if station is P8, add 20\n              TRUE ~ Chla) # else, keeep as previous value\n  ) %&gt;%\n  select(c(Station:Date), Chla)\n\n# A tibble: 62 × 3\n   Station Date        Chla\n   &lt;chr&gt;   &lt;date&gt;     &lt;dbl&gt;\n 1 P8      2020-01-16 20.6 \n 2 D7      2020-01-22  0.67\n 3 P8      2020-02-14 21.5 \n 4 D7      2020-02-20  2.15\n 5 P8      2020-03-03 21.4 \n 6 D7      2020-03-06  1.89\n 7 P8      2020-06-11 24.7 \n 8 D7      2020-06-17  1.74\n 9 P8      2020-07-13 26.4 \n10 D7      2020-07-16  2.79\n# ℹ 52 more rows",
    "crumbs": [
      "Day 2: 7/11/2024",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulation</span>"
    ]
  },
  {
    "objectID": "code/Day2_DataOrg.html#rename",
    "href": "code/Day2_DataOrg.html#rename",
    "title": "\n3  Data Manipulation\n",
    "section": "\n3.6 Rename",
    "text": "3.6 Rename\nSometimes, we want to rename our columns (eg. if working with multiple dataframes, we want the columns to be standardized). We can do this using the rename function from the dplyr package:\n\ndf_wq %&gt;%\n  rename(StationCode = Station)\n\n# A tibble: 62 × 20\n   StationCode Date        Chla Pheophytin TotAlkalinity DissAmmonia\n   &lt;chr&gt;       &lt;date&gt;     &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;\n 1 P8          2020-01-16  0.64       0.5             98        0.15\n 2 D7          2020-01-22  0.67       0.87            82        0.21\n 3 P8          2020-02-14  1.46       0.69            81        0.25\n 4 D7          2020-02-20  2.15       0.5             86        0.14\n 5 P8          2020-03-03  1.4        0.56            80        0.11\n 6 D7          2020-03-06  1.89       1.13            93        0.22\n 7 P8          2020-06-11  4.73       1.25            59        0.05\n 8 D7          2020-06-17  1.74       0.89            78        0.05\n 9 P8          2020-07-13  6.4        0.88            63        0.05\n10 D7          2020-07-16  2.79       0.85            80        0.05\n# ℹ 52 more rows\n# ℹ 14 more variables: DissNitrateNitrite &lt;dbl&gt;, DOC &lt;dbl&gt;, TOC &lt;dbl&gt;,\n#   DON &lt;dbl&gt;, TotPhos &lt;dbl&gt;, DissOrthophos &lt;dbl&gt;, TDS &lt;dbl&gt;, TSS &lt;dbl&gt;,\n#   TKN &lt;dbl&gt;, Depth &lt;dbl&gt;, Secchi &lt;dbl&gt;, Microcystis &lt;dbl&gt;,\n#   SpCndSurface &lt;dbl&gt;, WTSurface &lt;dbl&gt;",
    "crumbs": [
      "Day 2: 7/11/2024",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulation</span>"
    ]
  },
  {
    "objectID": "code/Day2_DataOrg.html#final-exercise",
    "href": "code/Day2_DataOrg.html#final-exercise",
    "title": "\n3  Data Manipulation\n",
    "section": "\n3.7 Final Exercise",
    "text": "3.7 Final Exercise\nUsing pipes, modify the df_wq dataframe as so:\n\nit’s assigned to a new object named df_new\nfilter Date to 2021 data only (hint: after ‘2020-12-31’, before ‘2022-12-31’)\nselect only the Station, Date, Chla, and Pheophytin columns\nmutate Station in-place so it’s a factor column\n\nChallenge:\n\nmutate Chla so it’s +20 specifically for the case when the month is April (04) and the station is P8\n\nassign this new dataframe to the object df_new\n\ncan you access the “original” df_new now? what happens if you re-run the code?\n\n\n\n\nCodedf_new &lt;- df_wq %&gt;%\n  filter(Date &gt; '2020-12-31' & Date &lt; '2022-12-31') %&gt;%\n  select(c(Station, Date, Chla, Pheophytin)) %&gt;%\n  mutate(Station = factor(Station))\n\nstr(df_new)\n\n\n\nCodedf_new &lt;- df_new %&gt;%\n  mutate(\n    Chla = case_when(\n      month(Date) == 04 & Station == 'P8' ~ Chla + 20,\n      TRUE ~ Chla\n    )\n  )\n\ndf_new",
    "crumbs": [
      "Day 2: 7/11/2024",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Manipulation</span>"
    ]
  }
]